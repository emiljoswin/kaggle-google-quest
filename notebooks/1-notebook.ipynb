{"cells":[{"metadata":{},"cell_type":"markdown","source":"1. Verified that the model class and original model definition via repeated functio calls have extremely close validation scores **(0.2998 for normal and 0.3042 class for class)** ie, they are probably same "},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"# Colab"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"colab_type":"code","executionInfo":{"elapsed":416690,"status":"error","timestamp":1578922904543,"user":{"displayName":"Emil Joswin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3fTReDoYuF-CGnvkmPxdSFOdnCwpwQNol9ghQ=s64","userId":"12652004406215465547"},"user_tz":300},"hidden":true,"id":"h1fl-jZnUbY5","outputId":"a71ee7b2-8042-486b-ea2e-320b73547c1d","trusted":false},"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","hidden":true,"id":"UqQkC_myUkuY","trusted":false},"cell_type":"code","source":"# ! cp -r drive/My\\ Drive/ml_projects/kaggle/google_quest/google-quest-challenge .","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":151},"colab_type":"code","executionInfo":{"elapsed":11265,"status":"ok","timestamp":1578878075653,"user":{"displayName":"Emil Joswin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3fTReDoYuF-CGnvkmPxdSFOdnCwpwQNol9ghQ=s64","userId":"12652004406215465547"},"user_tz":300},"hidden":true,"id":"vFM0QFyWVBz4","outputId":"5715fafe-d7ac-4e4f-f298-3787649a3d06","trusted":false},"cell_type":"code","source":"# !ls  drive/My\\ Drive/ml_projects/ml_datasets/nlp_pretrained/gensim-embeddings-dataset","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","hidden":true,"id":"QeU5zk-WUpUd","trusted":false},"cell_type":"code","source":"# ! cp drive/My\\ Drive/ml_projects/ml_datasets/nlp_pretrained/gensim-embeddings-dataset/glove.twitter.27B.200d.gensim .\n# ! cp drive/My\\ Drive/ml_projects/ml_datasets/nlp_pretrained/gensim-embeddings-dataset/glove.twitter.27B.200d.gensim.vectors.npy .","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Start"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"colab_type":"code","executionInfo":{"elapsed":27840,"status":"ok","timestamp":1578878092242,"user":{"displayName":"Emil Joswin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3fTReDoYuF-CGnvkmPxdSFOdnCwpwQNol9ghQ=s64","userId":"12652004406215465547"},"user_tz":300},"id":"OyoGX4jUT3vb","outputId":"fb215d5a-9233-47ee-d679-7a9928caa60d","trusted":true},"cell_type":"code","source":"from IPython.core.display import display, HTML\ndisplay(HTML(\"<style>.container { width:95% !important; }</style>\"))\ndisplay(HTML(\"<style>.run_this_cell {display: block !important;} </style\"))","execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>.container { width:95% !important; }</style>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>.run_this_cell {display: block !important;} </style"},"metadata":{}}]},{"metadata":{"colab":{},"colab_type":"code","id":"wLiLE7SaVWAn","trusted":true},"cell_type":"code","source":"%tensorflow_version 2.x ","execution_count":2,"outputs":[{"output_type":"stream","text":"UsageError: Line magic function `%tensorflow_version` not found.\n","name":"stderr"}]},{"metadata":{"colab":{},"colab_type":"code","id":"bQt1xaLzT3vd","trusted":true},"cell_type":"code","source":"import re\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Input, concatenate, LSTM, Bidirectional, Embedding, add, Dense\nfrom tensorflow.keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D\nfrom tensorflow.keras.models import Model\n\nfrom tensorflow.keras import models, layers, optimizers\n\n\nfrom datetime import datetime\nfrom typing import List, Dict, Tuple, Any\n\nfrom collections import Counter\nfrom tqdm import trange, tqdm, tnrange, tqdm_notebook\nfrom gensim.models import KeyedVectors\nfrom sklearn.model_selection import train_test_split","execution_count":3,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"B9RydZYvaDiQ","trusted":true},"cell_type":"code","source":"np.random.seed(42)\ntf.random.set_seed(42)","execution_count":4,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":1451,"status":"ok","timestamp":1578878309030,"user":{"displayName":"Emil Joswin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3fTReDoYuF-CGnvkmPxdSFOdnCwpwQNol9ghQ=s64","userId":"12652004406215465547"},"user_tz":300},"id":"nq9g_M92Vgq1","outputId":"a5f4a008-e41f-4309-a821-09c5930948b6","trusted":true},"cell_type":"code","source":"tf.__version__","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"'2.1.0-rc0'"},"metadata":{}}]},{"metadata":{"colab":{},"colab_type":"code","id":"lc7FPfs4T3vg","trusted":true},"cell_type":"code","source":"import os\n\nos.environ['KMP_DUPLICATE_LIB_OK']='True'","execution_count":6,"outputs":[]},{"metadata":{"colab_type":"text","id":"1TGVOD8XT3vj"},"cell_type":"markdown","source":"### Utility functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '\\xa0', '\\t',\n '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '\\u3000', '\\u202f',\n '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '«',\n '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]","execution_count":7,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"6Aq9OA4hT3vj","trusted":true},"cell_type":"code","source":"def clean_text(x):\n\n    x = str(x)\n    for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^`{|}~' + '“”’':\n        x = x.replace(punct, f' {punct}')\n   \n    for punct in '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n“”’\\'∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—_':\n        x = x.replace(punct, f' {punct}')\n        \n    for punct in puncts:\n        x = x.replace(punct, f' {punct}')\n \n    return x","execution_count":8,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"la2rU5NsT3vl","trusted":true},"cell_type":"code","source":"def _get_mispell(mispell_dict):\n    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n    return mispell_dict, mispell_re","execution_count":9,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"MoFpBlmiT3vo","trusted":true},"cell_type":"code","source":"mispell_dict = {\"usepackage\" : \"use package\",\n                'instrumentsettingsid':'instrumental settings id',\n                'RippleShaderProgram' : 'ripple shader program',\n                'ShaderProgramConstants':'shader program constants',\n                'storedElements':'stored elements',\n                'stackSize' : 'stack size',\n                '_':' ',\n                \"aren't\" : \"are not\",\n                \"can't\" : \"cannot\",\n                \"couldn't\" : \"could not\",\n                \"couldnt\" : \"could not\",\n                \"didn't\" : \"did not\",\n                \"doesn't\" : \"does not\",\n                \"doesnt\" : \"does not\",\n                \"don't\" : \"do not\",\n                \"hadn't\" : \"had not\",\n                \"hasn't\" : \"has not\",\n                \"haven't\" : \"have not\",\n                \"havent\" : \"have not\",\n                \"he'd\" : \"he would\",\n                \"he'll\" : \"he will\",\n                \"he's\" : \"he is\",\n                \"i'd\" : \"I would\",\n                \"i'd\" : \"I had\",\n                \"i'll\" : \"I will\",\n                \"i'm\" : \"I am\",\n                \"isn't\" : \"is not\",\n                \"it's\" : \"it is\",\n                \"it'll\":\"it will\",\n                \"i've\" : \"I have\",\n                \"let's\" : \"let us\",\n                \"mightn't\" : \"might not\",\n                \"mustn't\" : \"must not\",\n                \"shan't\" : \"shall not\",\n                \"she'd\" : \"she would\",\n                \"she'll\" : \"she will\",\n                \"she's\" : \"she is\",\n                \"shouldn't\" : \"should not\",\n                \"shouldnt\" : \"should not\",\n                \"that's\" : \"that is\",\n                \"thats\" : \"that is\",\n                \"there's\" : \"there is\",\n                \"theres\" : \"there is\",\n                \"they'd\" : \"they would\",\n                \"they'll\" : \"they will\",\n                \"they're\" : \"they are\",\n                \"theyre\":  \"they are\",\n                \"they've\" : \"they have\",\n                \"we'd\" : \"we would\",\n                \"we're\" : \"we are\",\n                \"weren't\" : \"were not\",\n                \"we've\" : \"we have\",\n                \"what'll\" : \"what will\",\n                \"what're\" : \"what are\",\n                \"what's\" : \"what is\",\n                \"what've\" : \"what have\",\n                \"where's\" : \"where is\",\n                \"who'd\" : \"who would\",\n                \"who'll\" : \"who will\",\n                \"who're\" : \"who are\",\n                \"who's\" : \"who is\",\n                \"who've\" : \"who have\",\n                \"won't\" : \"will not\",\n                \"wouldn't\" : \"would not\",\n                \"you'd\" : \"you would\",\n                \"you'll\" : \"you will\",\n                \"you're\" : \"you are\",\n                \"you've\" : \"you have\",\n                \"'re\": \" are\",\n                \"wasn't\": \"was not\",\n                \"we'll\":\" will\",\n                \"didn't\": \"did not\",\n                \"tryin'\":\"trying\"}","execution_count":10,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"26ypEMSLT3vq","trusted":true},"cell_type":"code","source":"mispellings, mispellings_re = _get_mispell(mispell_dict)","execution_count":11,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"7c_TchcCT3vs","trusted":true},"cell_type":"code","source":"def replace_typical_misspell(text):\n    def replace(match):\n        return mispellings[match.group(0)]\n\n    return mispellings_re.sub(replace, text)","execution_count":12,"outputs":[]},{"metadata":{"colab_type":"text","id":"CR8RjZmpT3vu"},"cell_type":"markdown","source":"### Loading Data"},{"metadata":{"colab":{},"colab_type":"code","id":"JZ2FDG8MT3vv","trusted":true},"cell_type":"code","source":"train_loc = '/kaggle/input/google-quest-challenge/train.csv'\ntest_loc= '/kaggle/input/google-quest-challenge/test.csv'\n\n# train_loc = 'google-quest-challenge/train.csv'\n# test_loc= 'google-quest-challenge/test.csv'\n\ntrain_df = pd.read_csv(train_loc)\ntest_df = pd.read_csv(test_loc)\n","execution_count":13,"outputs":[]},{"metadata":{"colab_type":"text","id":"BFcJKnZ9T3vy"},"cell_type":"markdown","source":"### Preprocessing"},{"metadata":{"colab":{},"colab_type":"code","id":"SonttmKnT3vy","trusted":true},"cell_type":"code","source":"train_df[\"question_body\"] = train_df[\"question_body\"].apply(clean_text)\ntrain_df[\"question_body\"] = train_df[\"question_body\"].apply(replace_typical_misspell)\n\ntrain_df[\"question_title\"] = train_df[\"question_title\"].apply(clean_text)\ntrain_df[\"question_title\"] = train_df[\"question_title\"].apply(replace_typical_misspell)\n\ntrain_df[\"category\"] = train_df[\"category\"].apply(clean_text)\ntrain_df[\"category\"] = train_df[\"category\"].apply(replace_typical_misspell)\n\ntrain_df[\"answer\"] = train_df[\"answer\"].apply(clean_text)\ntrain_df[\"answer\"] = train_df[\"answer\"].apply(replace_typical_misspell)\n\n\ntest_df[\"question_body\"] = test_df[\"question_body\"].apply(clean_text)\ntest_df[\"question_body\"] = test_df[\"question_body\"].apply(replace_typical_misspell)\n\ntest_df[\"question_title\"] = test_df[\"question_title\"].apply(clean_text)\ntest_df[\"question_title\"] = test_df[\"question_title\"].apply(replace_typical_misspell)\n\ntest_df[\"category\"] = test_df[\"category\"].apply(clean_text)\ntest_df[\"category\"] = test_df[\"category\"].apply(replace_typical_misspell)\n\ntest_df[\"answer\"] = test_df[\"answer\"].apply(clean_text)\ntest_df[\"answer\"] = test_df[\"answer\"].apply(replace_typical_misspell)","execution_count":14,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"I7vq6-EDT3v0","trusted":true},"cell_type":"code","source":"question_body = train_df['question_body']\nanswer = train_df['answer']\nquestion_title = train_df[\"question_title\"]\ncategory = train_df[\"category\"]\n\nquestion_body_test = test_df['question_body']\nanswer_test = test_df['answer']\nquestion_title_test = test_df[\"question_title\"]\ncategory_test = test_df[\"category\"]","execution_count":15,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"lmPgad44T3v2","trusted":true},"cell_type":"code","source":"target = train_df[train_df.columns[-30:]]","execution_count":16,"outputs":[]},{"metadata":{"colab_type":"text","id":"KRryeoqAT3v5"},"cell_type":"markdown","source":"### Creating Tokenziers"},{"metadata":{"colab":{},"colab_type":"code","id":"DJceUF8qT3v6","trusted":true},"cell_type":"code","source":"all_text = pd.concat([\n                    train_df['question_body'],\n                     train_df['answer'],\n                     test_df['question_body'],\n                     test_df['answer'],\n                     train_df[\"question_title\"],\n                     train_df[\"category\"],\n                     test_df[\"question_title\"],\n                     test_df[\"category\"]\n                    ])","execution_count":17,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":449,"status":"ok","timestamp":1578878325274,"user":{"displayName":"Emil Joswin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3fTReDoYuF-CGnvkmPxdSFOdnCwpwQNol9ghQ=s64","userId":"12652004406215465547"},"user_tz":300},"id":"vk_RL_VvT3v7","outputId":"0f8f7ca3-643f-4970-f268-5f16c0c061bd","trusted":true},"cell_type":"code","source":"len(train_df), len(test_df), 6079*4 + 476 * 4, len(all_text)","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"(6079, 476, 26220, 26220)"},"metadata":{}}]},{"metadata":{"colab":{},"colab_type":"code","id":"TivBnUFgT3v-","trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(num_words=1000000, lower=False,filters='')\n\ntokenizer.fit_on_texts(all_text)","execution_count":19,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":2967,"status":"ok","timestamp":1578878329103,"user":{"displayName":"Emil Joswin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3fTReDoYuF-CGnvkmPxdSFOdnCwpwQNol9ghQ=s64","userId":"12652004406215465547"},"user_tz":300},"id":"J1KJ9QHuT3wA","outputId":"df61c9d6-873c-4ce1-dab0-cd142f02b971","trusted":true},"cell_type":"code","source":"len(tokenizer.word_counts), tokenizer.word_index['the'], tokenizer.word_index['ABC']","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"(100498, 4, 8783)"},"metadata":{}}]},{"metadata":{"colab":{},"colab_type":"code","id":"Whxhk7tuT3wC","trusted":true},"cell_type":"code","source":"question_body = tokenizer.texts_to_sequences(question_body)\nanswer = tokenizer.texts_to_sequences(answer)\nquestion_title = tokenizer.texts_to_sequences(question_title)\ncategory = tokenizer.texts_to_sequences(category)\n\nquestion_body_test = tokenizer.texts_to_sequences(question_body_test)\nanswer_test = tokenizer.texts_to_sequences(answer_test)\nquestion_title_test = tokenizer.texts_to_sequences(question_title_test)\ncategory_test = tokenizer.texts_to_sequences(category_test)","execution_count":21,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":1544,"status":"ok","timestamp":1578878329420,"user":{"displayName":"Emil Joswin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3fTReDoYuF-CGnvkmPxdSFOdnCwpwQNol9ghQ=s64","userId":"12652004406215465547"},"user_tz":300},"id":"BzYwGh5XT3wE","outputId":"7f7ffd31-f575-40c9-f450-a0d42031a46a","trusted":true},"cell_type":"code","source":"len(question_body), len(question_body[0])","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"(6079, 174)"},"metadata":{}}]},{"metadata":{"colab":{},"colab_type":"code","id":"Eh5XnfXvT3wJ","trusted":true},"cell_type":"code","source":"vocab_size = len(tokenizer.word_index) + 1\nmaxlen = 245","execution_count":23,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"mVirIudhT3wM","trusted":true},"cell_type":"code","source":"question_body = pad_sequences(question_body, padding='post', maxlen=maxlen)\nanswer = pad_sequences(answer, padding='post', maxlen=maxlen)\nquestion_title = pad_sequences(question_title, padding='post', maxlen=maxlen)\ncategory = pad_sequences(category, padding='post', maxlen=maxlen)\n\n\nquestion_body_test = pad_sequences(question_body_test, padding='post', maxlen=maxlen)\nanswer_test = pad_sequences(answer_test, padding='post', maxlen=maxlen)\nquestion_title_test = pad_sequences(question_title_test, padding='post', maxlen=maxlen)\ncategory_test = pad_sequences(category_test, padding='post', maxlen=maxlen)","execution_count":24,"outputs":[]},{"metadata":{"colab_type":"text","id":"OWMWifotT3wO"},"cell_type":"markdown","source":"### Build embedding matrix for the full dataset\n\nGensim word vectors can be found here https://www.kaggle.com/iezepov/gensim-embeddings-dataset\n\nAll UNK tokens will be 0s. This is different from the NLP project, where the UNK tokens are the average of the matrix."},{"metadata":{"colab":{},"colab_type":"code","id":"YWyKvf9JT3wO","trusted":true},"cell_type":"code","source":"emb_size = 200\n\ndef build_matrix(word_index, path):\n    embedding_index = KeyedVectors.load(path, mmap='r')\n    embedding_matrix = np.zeros((len(word_index) + 1, emb_size))\n    for word, i in word_index.items():\n        for candidate in [word, word.lower()]:\n            if candidate in embedding_index:\n                embedding_matrix[i] = embedding_index[candidate]\n                break\n    return embedding_matrix","execution_count":25,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"colab_type":"code","executionInfo":{"elapsed":4812,"status":"ok","timestamp":1578878338420,"user":{"displayName":"Emil Joswin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3fTReDoYuF-CGnvkmPxdSFOdnCwpwQNol9ghQ=s64","userId":"12652004406215465547"},"user_tz":300},"id":"MK0uZLtXT3wQ","outputId":"4782009f-1c0f-4666-b153-717b1f40e1ae","trusted":true},"cell_type":"code","source":"# EMBEDDING_FILES = ['/Users/emiljoswin/study/playground/jupyter_notebooks/NLP/crawl-300d-2M.gensim', \n#                   '/Users/emiljoswin/study/playground/jupyter_notebooks/NLP/glove.840B.300d.gensim']\n\nEMBEDDING_FILES = ['/kaggle/input/gensim-word-embeddings/glove.twitter.27B.200d.gensim']\n\n# EMBEDDING_FILES = ['../../NLP/pre-trained-weights/gensim-embeddings-dataset/glove.twitter.27B.200d.gensim']\n\nembedding_index = KeyedVectors.load(EMBEDDING_FILES[0], mmap='r')\n# embedding_index = KeyedVectors.load(EMBEDDING_FILES[1], mmap='r')","execution_count":26,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"colab_type":"code","executionInfo":{"elapsed":8369,"status":"ok","timestamp":1578878342107,"user":{"displayName":"Emil Joswin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3fTReDoYuF-CGnvkmPxdSFOdnCwpwQNol9ghQ=s64","userId":"12652004406215465547"},"user_tz":300},"id":"8rIFw0osT3wS","outputId":"0ae00de4-3340-484f-d1e0-61b18d3297af","trusted":true},"cell_type":"code","source":"m1 = build_matrix(tokenizer.word_index, EMBEDDING_FILES[0])\n# m2 = build_matrix(tokenizer.word_index, EMBEDDING_FILES[1])\n# m1.shape, m2.shape, \nm1.shape","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"(100499, 200)"},"metadata":{}}]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":923,"status":"ok","timestamp":1578878342372,"user":{"displayName":"Emil Joswin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3fTReDoYuF-CGnvkmPxdSFOdnCwpwQNol9ghQ=s64","userId":"12652004406215465547"},"user_tz":300},"id":"_8QlZPaQT3wY","outputId":"8b2dfef8-3056-482a-954c-12626f3ea503","trusted":true},"cell_type":"code","source":"# embedding_matrix = np.concatenate([m1, m2], axis=-1)\n# embedding_matrix.shape\n\nembedding_matrix = m1\nembedding_matrix.shape","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"(100499, 200)"},"metadata":{}}]},{"metadata":{"colab_type":"text","id":"UenY-gXKCfgV"},"cell_type":"markdown","source":"# Train Test Split"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":1408,"status":"ok","timestamp":1578887787987,"user":{"displayName":"Emil Joswin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3fTReDoYuF-CGnvkmPxdSFOdnCwpwQNol9ghQ=s64","userId":"12652004406215465547"},"user_tz":300},"id":"ChjGCi33C39o","outputId":"0b2bd082-15fe-49d3-b5a2-82d66f514a18","trusted":true},"cell_type":"code","source":"X = concatenate([question_body, question_title, category, answer], 1)\nprint(X.shape)\nY = target.to_numpy()\nprint(Y.shape)\n\ntest_original = concatenate([question_body_test, question_title_test, category_test, answer_test], 1)\nprint(test_original.shape)","execution_count":29,"outputs":[{"output_type":"stream","text":"(6079, 980)\n(6079, 30)\n(476, 980)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"total = 6079\nval_size = 700\n\np = np.random.permutation(list(range(total)))\n\nval_idx = p[:val_size]\ntrain_idx = p[val_size:]\n\ntrain_x = tf.gather(X, train_idx)\ntrain_y = tf.gather(Y, train_idx)\n\nval_x = tf.gather(X, val_idx)\nval_y = tf.gather(Y, val_idx)\n\nprint(train_x.shape, train_y.shape, val_x.shape, val_y.shape)\n","execution_count":30,"outputs":[{"output_type":"stream","text":"(5379, 980) (5379, 30) (700, 980) (700, 30)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(val_idx)","execution_count":31,"outputs":[{"output_type":"stream","text":"[3320  296  346 5001  544 5199 6071 1684 5502 4623 2057 5619 2223 3039\n 1142 2917 3641  747  586 1268 3690 1323 3919 3193 4722 1718 5058 2271\n 2570 3469 2166 5790 1566 2770 3047  810 5888 1027 3295  233 1049 5602\n  626 2578 4624 4151  167 2414 1747 5979 3305 1119 2980 1564  408 3574\n 1335 5740 5908 4710 3398 3323 4314 3750 5355 3286 1330  576  254 2303\n 4309  625 2441 4974 3181 1471 1507 2168 5419  932 3765   79 4937 2574\n 1033   23 3464 5325 4850 3614 4765 4828 2133 4428 1720  565 4764 5933\n  800 4215 2963 5775 5077  323 4884 5223 3395 1370 1044 4038 2457 3648\n 4301   37 3333 1509  881 4449 3889 3770 3491 1046 4943 3012 6038 2462\n 4534 3583 4211 2229 1732 2251 4216 2843 4563 5171  879 4900   84 2199\n 3967  960  907  308 4883  691 2409 5389 6052 3578 1599 4157 4783 3126\n 2018 2346 4322 4956 5633 4591  501 3426 5900 1261   93 1662  599 2351\n  472 3023 1496 2344  476 5679 5221 1454 3580 1225 3918 3384 3162  185\n 4053  228  977  622 2002 2759 2922 3934 3132 1951  157 2927 1407 2406\n 3393 5105 2676 2858 2357 3422 2314 5047 1978  263 5645 1175  156 5467\n  465 1002 2937   31  604  534 3290 3754 5850  319 3346 2029 2995 1215\n 2317  177  221 3116 5074 5267 2118 3916 4040 2998 1406 4283  401 2985\n 1223 4075 5670 3838 5349 4290 3515 3372 3095  655 2328  561 1934 5517\n 4260 1345   80 4618 2981 5817  705 3932 2402 5060 1726 1433  712 3250\n  469 3979 1832 1480 1192 4166 4902 6016 1609 3194 2410 5303 5789 2119\n 4305 2167 2536 1728 2209 4628 4153 5238 1545  865 5352 1672 1244 3125\n 5137 3617 5368 4454   50 4085 6010 1101  730 5738 3678 4589 1297 3739\n 2531 5015 6034 2943 3927 1965 5614 3450 2778 1039 5200 5880 4217 2025\n 1400 2173  811 5652  239 5629  199 4228  706 6032 5781 2244 4099 2609\n  535 2834  101 5624 1883  259 2107  742 1084 5690 3586 1419 3528 5008\n 1357 5902 3107 3922 4519 2042 1745 2177 3337 1973 2589 2715 1032 1144\n 4088 3539 3842 4335 5333 4567 3240 3516 3396 5480 4689  808 3857 6051\n 3105  506 1961  324 4048 3892  325 3353 2897  132 2602 4823 2732  787\n 4979 5089 4938 6004 2228 2077  553 4063 1864 5529 5239 1870  683  783\n 5407  371 5626 1103 1695 5862 1670 5491  168  710 4674 3833 2908 1893\n  198 4691 2881 1741 1919 2868 1451 2451 5635  230 5153 4532 1263 2792\n 2420 1788 1383 5362  538 2638   17 1501 4030 3880 1074 3971  812  439\n 5460 4863 3113 4991 5219 3559 3318 1617 3501 4663 3955 4894  672 1769\n  994 2789 4365 5263 2272 1038 1220  393 1170  279 3021 2232 4273 5156\n 5879 4339   14 1912 2318 5548 1557 4010 5684  410 3685 2913 4015 1554\n 2245   65 2471 1212 5010 1888 2905  351 5174 4140 5007 1740 4816 3737\n 2329 4912   88 2596 5875  969 2845 4808 4597 5193 3200 1129 5647 1630\n  420  926  373 5394 3357 1163 2518 1022 3334 5121  181 4526 2431 2669\n 4439 3879 3628 2323 5780 1700  530 5438 1963 3454 5109 4031 3658 5599\n 4384 2268 2879 2857 2802 5829 1699 5445 4317 4714   15 5493 3657 5583\n 3907 4013 2550 1820 6028 2503 2948 2098 3557 4690 5761 4358 5045 2689\n 4374 4601 4763 6023 2045 1835 2142 5099    8 1954 2887 4122 2080 4990\n 2380  549 3914 5571 1634  426   33 1075   44 1350 4925 3483 1971  681\n 4919 5159 3749 2642   63 1744 2313 4222 5346  227 3830 4315 1242 2691\n 2447 3049 3819 5774 1782 2477 4615 4461 2603 1253 2370 2302 5962 5615\n 4750 4584 3164 4944 4137 4471 5160  473 1536  696  297  303 3098 6030\n 4480 4259 4769 3795 3275 1862  240 5395 2788 5839 2941 2722  805 1193\n 4434 2803 1671 4634 4762 5782 2210 5468 4876  333  676 2316 2663 4270\n 1499 4292 1042 1983 4641 2829 2138  247 1694 3011 1097 4844 5869 5828\n 5728  746 5948 4862 5838 5714 3128 4320 3799  598 4790  315 1172 1360]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_x = tf.convert_to_tensor(val_x)\nval_y = tf.convert_to_tensor(val_y)\n\ntrain_x = tf.convert_to_tensor(train_x)\ntrain_y = tf.convert_to_tensor(train_y)","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x.shape, train_y.shape, val_x.shape, val_y.shape","execution_count":33,"outputs":[{"output_type":"execute_result","execution_count":33,"data":{"text/plain":"(TensorShape([5379, 980]),\n TensorShape([5379, 30]),\n TensorShape([700, 980]),\n TensorShape([700, 30]))"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Evaluate"},{"metadata":{"colab":{},"colab_type":"code","id":"EWIA7hdbpcEZ","trusted":true},"cell_type":"code","source":"from scipy.stats import spearmanr\nimport math\n\ndef calculate_mean_spearman_co(a, b):\n    \"\"\"\n        Calculates spearmans correlation coefficient \n        https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient\n        \n        In the scipy implementation if you pass x and y and if one of them is composed of all same values,\n        then it returns nan. I am changing those nans to zeros\n    \"\"\"\n    # print(a.shape, b.shape, len(a.shape))\n    # print(a, b)\n    if len(a.shape) == 1:\n        return 0\n\n    if a.shape[0] is None and a.shape[1] is None:\n         return 0\n         \n    ans = [spearmanr(a[:, i], b[:, i])[0] for i in range(a.shape[1])]\n\n    ans = [0. if math.isnan(elem) else elem for elem in ans]\n    return np.mean(ans), ans","execution_count":34,"outputs":[]},{"metadata":{"colab_type":"text","id":"d_-i384iDTgz"},"cell_type":"markdown","source":"# Extras"},{"metadata":{"colab":{},"colab_type":"code","id":"U6Xe49SJDUfV","trusted":true},"cell_type":"code","source":"LSTM_UNITS = 64\nDENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\nBATCH_SIZE = 128\nEPOCHS = 10","execution_count":51,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"kG5WumZ7DXL-","trusted":true},"cell_type":"code","source":"words = Input(shape=(None,))","execution_count":52,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"x1W2klM3DfXF","trusted":true},"cell_type":"code","source":"x = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(words)\nx = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(x)\nx = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(x)\n\nhidden = concatenate([\n        GlobalMaxPooling1D()(x),\n        GlobalAveragePooling1D()(x),\n    ])\n\nhidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\nhidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])","execution_count":53,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"Q-z0nvBCDhxU","trusted":true},"cell_type":"code","source":"result = Dense(30, activation='sigmoid')(hidden)","execution_count":54,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"wzJcTMZODkJ9","trusted":true},"cell_type":"code","source":"model2 = Model(inputs=words, outputs=[result])\nmodel2.compile(loss='mean_squared_error', optimizer='rmsprop',metrics=['mae'])","execution_count":55,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":605},"colab_type":"code","executionInfo":{"elapsed":2023,"status":"ok","timestamp":1578887993780,"user":{"displayName":"Emil Joswin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3fTReDoYuF-CGnvkmPxdSFOdnCwpwQNol9ghQ=s64","userId":"12652004406215465547"},"user_tz":300},"id":"RD9xp-VMDmS0","outputId":"a4d8ebbb-584b-4e72-ac86-7f6021ec0e11","trusted":true},"cell_type":"code","source":"# model2.summary()","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.fit(\n            train_x, train_y,\n            batch_size=256,\n            epochs=20,\n            verbose=1,\n        )","execution_count":57,"outputs":[{"output_type":"stream","text":"Train on 5379 samples\nEpoch 1/20\n5379/5379 [==============================] - 11s 2ms/sample - loss: 0.0673 - mae: 0.1898\nEpoch 2/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0577 - mae: 0.1674\nEpoch 3/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0559 - mae: 0.1630\nEpoch 4/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0545 - mae: 0.1608\nEpoch 5/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0540 - mae: 0.1589\nEpoch 6/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0521 - mae: 0.1560\nEpoch 7/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0524 - mae: 0.1554\nEpoch 8/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0514 - mae: 0.1538\nEpoch 9/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0502 - mae: 0.1514\nEpoch 10/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0499 - mae: 0.1505\nEpoch 11/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0492 - mae: 0.1497\nEpoch 12/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0477 - mae: 0.1468\nEpoch 13/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0476 - mae: 0.1465\nEpoch 14/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0466 - mae: 0.1444\nEpoch 15/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0462 - mae: 0.1440\nEpoch 16/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0456 - mae: 0.1420\nEpoch 17/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0452 - mae: 0.1418\nEpoch 18/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0441 - mae: 0.1398\nEpoch 19/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0442 - mae: 0.1399\nEpoch 20/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0432 - mae: 0.1386\n","name":"stdout"},{"output_type":"execute_result","execution_count":57,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f541f447198>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_predictions = model2.predict(val_x)\nm, _ = calculate_mean_spearman_co(val_predictions, val_y)\nprint(\"val_spearman\", m)","execution_count":58,"outputs":[{"output_type":"stream","text":"val_spearman 0.2998429770872825\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Model as a class"},{"metadata":{"trusted":true},"cell_type":"code","source":"LSTM_UNITS = 64\nDENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\nBATCH_SIZE = 128\nEPOCHS = 10\nOUTPUT_CLASSES = 30","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MyModel(models.Model):\n    def __init__(self, embedding_matrix):\n        super(MyModel, self).__init__()\n        self.emb = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)\n        self.b1 = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))\n        self.b2 = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))\n#         self.attn_weight = tf.Variable(tf.random.normal((LSTM_UNITS*2, 1)))\n        self.g1 = GlobalMaxPooling1D()\n        self.g2 = GlobalAveragePooling1D()\n        self.d1 = Dense(DENSE_HIDDEN_UNITS, activation='relu')\n        self.d2 = Dense(DENSE_HIDDEN_UNITS, activation='relu')\n        self.linear = Dense(OUTPUT_CLASSES, activation='sigmoid')\n        \n    def attn(self, inputs):\n        \"\"\"\n            inputs: [bsz x 980 x LSTM_UNITS*2]\n            output: [bsz x LSTM_UNITS]\n        \"\"\"\n        \n        # (1 x 128) (bsz x seq x 128 )T  => (2 x seq)\n        check = tf.einsum('ij,kjm->kim',\n                          tf.transpose(self.attn_weight), \n                          tf.transpose(inputs, [0, 2, 1])) # (bsz x 1 x 980) - a score for each time step\n        \n        check = tf.squeeze(check) # (bsz x 980)\n        check = tf.nn.softmax(check, axis=1) # attention weight (bsz x 980)\n        \n        #(bsz x seq x 128)T (bsz x seq) => (bsz x 128)\n        check = tf.einsum('ijk,ki->ij', \n                          tf.transpose(inputs, [0, 2, 1]), \n                          tf.transpose(check) ) # (bsz x LSTM_UNITS) - best of each 980 time-steps\n        \n        return check\n\n        \n        \n    def call(self, inputs):\n        x = self.emb(inputs)\n        x = self.b1(x)\n        x = self.b2(x)\n#         x1 = self.attn(x) # (bsz x LSTM_UNITS*2)\n#         x2 = self.attn(x)\n        x = concatenate([self.g1(x), self.g2(x)])\n        \n        x = add([x, self.d1(x)])\n        x = add([x, self.d2(x)])\n        x = self.linear(x)\n        return x","execution_count":43,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model3 = MyModel(embedding_matrix)","execution_count":44,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"out = model3(train_x[0:2, :])","execution_count":45,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out.shape","execution_count":46,"outputs":[{"output_type":"execute_result","execution_count":46,"data":{"text/plain":"TensorShape([2, 30])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model3.compile(loss='mean_squared_error', optimizer='rmsprop',metrics=['mae'])","execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model3.fit(\n            train_x, train_y,\n            batch_size=256,\n            epochs=20,\n            verbose=1,\n        )","execution_count":48,"outputs":[{"output_type":"stream","text":"Train on 5379 samples\nEpoch 1/20\n5379/5379 [==============================] - 13s 2ms/sample - loss: 0.0709 - mae: 0.1959\nEpoch 2/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0576 - mae: 0.1679\nEpoch 3/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0562 - mae: 0.1638\nEpoch 4/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0545 - mae: 0.1608\nEpoch 5/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0541 - mae: 0.1592\nEpoch 6/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0526 - mae: 0.1567\nEpoch 7/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0514 - mae: 0.1538\nEpoch 8/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0508 - mae: 0.1528\nEpoch 9/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0498 - mae: 0.1507\nEpoch 10/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0490 - mae: 0.1492\nEpoch 11/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0486 - mae: 0.1484\nEpoch 12/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0474 - mae: 0.1463\nEpoch 13/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0471 - mae: 0.1456\nEpoch 14/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0462 - mae: 0.1438\nEpoch 15/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0457 - mae: 0.1428\nEpoch 16/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0452 - mae: 0.1414\nEpoch 17/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0448 - mae: 0.1407\nEpoch 18/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0435 - mae: 0.1387\nEpoch 19/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0438 - mae: 0.1385\nEpoch 20/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0428 - mae: 0.1375\n","name":"stdout"},{"output_type":"execute_result","execution_count":48,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f54140fe710>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_predictions = model3.predict(val_x)\nm, _ = calculate_mean_spearman_co(val_predictions, val_y)\nprint(\"val_spearman\", m)","execution_count":50,"outputs":[{"output_type":"stream","text":"val_spearman 0.30425691567246776\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Saving the predictions"},{"metadata":{"trusted":false},"cell_type":"code","source":"predictions = model3.predict(test_original)\nprint(predictions.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"target_cols = ['question_asker_intent_understanding',\n       'question_body_critical', 'question_conversational',\n       'question_expect_short_answer', 'question_fact_seeking',\n       'question_has_commonly_accepted_answer',\n       'question_interestingness_others', 'question_interestingness_self',\n       'question_multi_intent', 'question_not_really_a_question',\n       'question_opinion_seeking', 'question_type_choice',\n       'question_type_compare', 'question_type_consequence',\n       'question_type_definition', 'question_type_entity',\n       'question_type_instructions', 'question_type_procedure',\n       'question_type_reason_explanation', 'question_type_spelling',\n       'question_well_written', 'answer_helpful',\n       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n       'answer_satisfaction', 'answer_type_instructions',\n       'answer_type_procedure', 'answer_type_reason_explanation',\n       'answer_well_written']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"loc = '/kaggle/input/google-quest-challenge/sample_submission.csv'\n# loc = 'google-quest-challenge/sample_submission.csv'\nsub = pd.read_csv(loc)\n\nfor col_index, col in enumerate(target_cols):\n    sub[col] = predictions[:, col_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sub.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"1-notebook.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":1}