{"cells":[{"metadata":{},"cell_type":"markdown","source":"####  NOTES\n>1. Verified that the model class and original model definition via repeated functio calls have extremely close validation scores **(0.2998 for normal and 0.3042 class for class)** ie, they are probably same.\n>2. Added better code cleaning functionalities and mis-spelling corrections.\n\n\n####  TODO\n>1. There is text augmenter library https://github.com/makcedward/nlpaug/blob/master/example/textual_augmenter.ipynb"},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"# Colab"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"colab_type":"code","executionInfo":{"elapsed":416690,"status":"error","timestamp":1578922904543,"user":{"displayName":"Emil Joswin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3fTReDoYuF-CGnvkmPxdSFOdnCwpwQNol9ghQ=s64","userId":"12652004406215465547"},"user_tz":300},"hidden":true,"id":"h1fl-jZnUbY5","outputId":"a71ee7b2-8042-486b-ea2e-320b73547c1d","trusted":false},"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","hidden":true,"id":"UqQkC_myUkuY","trusted":false},"cell_type":"code","source":"# ! cp -r drive/My\\ Drive/ml_projects/kaggle/google_quest/google-quest-challenge .","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":151},"colab_type":"code","executionInfo":{"elapsed":11265,"status":"ok","timestamp":1578878075653,"user":{"displayName":"Emil Joswin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3fTReDoYuF-CGnvkmPxdSFOdnCwpwQNol9ghQ=s64","userId":"12652004406215465547"},"user_tz":300},"hidden":true,"id":"vFM0QFyWVBz4","outputId":"5715fafe-d7ac-4e4f-f298-3787649a3d06","trusted":false},"cell_type":"code","source":"# !ls  drive/My\\ Drive/ml_projects/ml_datasets/nlp_pretrained/gensim-embeddings-dataset","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","hidden":true,"id":"QeU5zk-WUpUd","trusted":false},"cell_type":"code","source":"# ! cp drive/My\\ Drive/ml_projects/ml_datasets/nlp_pretrained/gensim-embeddings-dataset/glove.twitter.27B.200d.gensim .\n# ! cp drive/My\\ Drive/ml_projects/ml_datasets/nlp_pretrained/gensim-embeddings-dataset/glove.twitter.27B.200d.gensim.vectors.npy .","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Start"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"colab_type":"code","executionInfo":{"elapsed":27840,"status":"ok","timestamp":1578878092242,"user":{"displayName":"Emil Joswin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3fTReDoYuF-CGnvkmPxdSFOdnCwpwQNol9ghQ=s64","userId":"12652004406215465547"},"user_tz":300},"id":"OyoGX4jUT3vb","outputId":"fb215d5a-9233-47ee-d679-7a9928caa60d","trusted":true},"cell_type":"code","source":"from IPython.core.display import display, HTML\ndisplay(HTML(\"<style>.container { width:95% !important; }</style>\"))\ndisplay(HTML(\"<style>.run_this_cell {display: block !important;} </style\"))","execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>.container { width:95% !important; }</style>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>.run_this_cell {display: block !important;} </style"},"metadata":{}}]},{"metadata":{"colab":{},"colab_type":"code","id":"wLiLE7SaVWAn","trusted":true},"cell_type":"code","source":"%tensorflow_version 2.x ","execution_count":2,"outputs":[{"output_type":"stream","text":"UsageError: Line magic function `%tensorflow_version` not found.\n","name":"stderr"}]},{"metadata":{"colab":{},"colab_type":"code","id":"bQt1xaLzT3vd","trusted":true},"cell_type":"code","source":"import re\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Input, concatenate, LSTM, Bidirectional, Embedding, add, Dense\nfrom tensorflow.keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D\nfrom tensorflow.keras.models import Model\n\nfrom tensorflow.keras import models, layers, optimizers\n\n\nfrom datetime import datetime\nfrom typing import List, Dict, Tuple, Any\n\nfrom collections import Counter\nfrom tqdm import trange, tqdm, tnrange, tqdm_notebook\nfrom gensim.models import KeyedVectors\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.model_selection import KFold","execution_count":61,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"B9RydZYvaDiQ","trusted":true},"cell_type":"code","source":"np.random.seed(42)\ntf.random.set_seed(42)","execution_count":4,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":1451,"status":"ok","timestamp":1578878309030,"user":{"displayName":"Emil Joswin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3fTReDoYuF-CGnvkmPxdSFOdnCwpwQNol9ghQ=s64","userId":"12652004406215465547"},"user_tz":300},"id":"nq9g_M92Vgq1","outputId":"a5f4a008-e41f-4309-a821-09c5930948b6","trusted":true},"cell_type":"code","source":"tf.__version__","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"'2.1.0-rc0'"},"metadata":{}}]},{"metadata":{"colab":{},"colab_type":"code","id":"lc7FPfs4T3vg","trusted":true},"cell_type":"code","source":"import os\n\nos.environ['KMP_DUPLICATE_LIB_OK']='True'","execution_count":6,"outputs":[]},{"metadata":{"colab_type":"text","id":"1TGVOD8XT3vj"},"cell_type":"markdown","source":"### Utility functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '\\xa0', '\\t',\n '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '\\u3000', '\\u202f',\n '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '«',\n '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]","execution_count":7,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"6Aq9OA4hT3vj","trusted":true},"cell_type":"code","source":"def clean_text(x):\n\n    x = str(x)\n    for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^`{|}~' + '“”’':\n        x = x.replace(punct, f' {punct}')\n   \n    for punct in '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n“”’\\'∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—_':\n        x = x.replace(punct, f' {punct}')\n        \n    for punct in puncts:\n        x = x.replace(punct, f' {punct}')\n \n    return x","execution_count":8,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"la2rU5NsT3vl","trusted":true},"cell_type":"code","source":"def _get_mispell(mispell_dict):\n    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n    return mispell_dict, mispell_re","execution_count":9,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"MoFpBlmiT3vo","trusted":true},"cell_type":"code","source":"mispell_dict = {\"usepackage\" : \"use package\",\n                'instrumentsettingsid':'instrumental settings id',\n                'RippleShaderProgram' : 'ripple shader program',\n                'ShaderProgramConstants':'shader program constants',\n                'storedElements':'stored elements',\n                'stackSize' : 'stack size',\n                '_':' ',\n                \"aren't\" : \"are not\",\n                \"can't\" : \"cannot\",\n                \"couldn't\" : \"could not\",\n                \"couldnt\" : \"could not\",\n                \"didn't\" : \"did not\",\n                \"doesn't\" : \"does not\",\n                \"doesnt\" : \"does not\",\n                \"don't\" : \"do not\",\n                \"hadn't\" : \"had not\",\n                \"hasn't\" : \"has not\",\n                \"haven't\" : \"have not\",\n                \"havent\" : \"have not\",\n                \"he'd\" : \"he would\",\n                \"he'll\" : \"he will\",\n                \"he's\" : \"he is\",\n                \"i'd\" : \"I would\",\n                \"i'd\" : \"I had\",\n                \"i'll\" : \"I will\",\n                \"i'm\" : \"I am\",\n                \"isn't\" : \"is not\",\n                \"it's\" : \"it is\",\n                \"it'll\":\"it will\",\n                \"i've\" : \"I have\",\n                \"let's\" : \"let us\",\n                \"mightn't\" : \"might not\",\n                \"mustn't\" : \"must not\",\n                \"shan't\" : \"shall not\",\n                \"she'd\" : \"she would\",\n                \"she'll\" : \"she will\",\n                \"she's\" : \"she is\",\n                \"shouldn't\" : \"should not\",\n                \"shouldnt\" : \"should not\",\n                \"that's\" : \"that is\",\n                \"thats\" : \"that is\",\n                \"there's\" : \"there is\",\n                \"theres\" : \"there is\",\n                \"they'd\" : \"they would\",\n                \"they'll\" : \"they will\",\n                \"they're\" : \"they are\",\n                \"theyre\":  \"they are\",\n                \"they've\" : \"they have\",\n                \"we'd\" : \"we would\",\n                \"we're\" : \"we are\",\n                \"weren't\" : \"were not\",\n                \"we've\" : \"we have\",\n                \"what'll\" : \"what will\",\n                \"what're\" : \"what are\",\n                \"what's\" : \"what is\",\n                \"what've\" : \"what have\",\n                \"where's\" : \"where is\",\n                \"who'd\" : \"who would\",\n                \"who'll\" : \"who will\",\n                \"who're\" : \"who are\",\n                \"who's\" : \"who is\",\n                \"who've\" : \"who have\",\n                \"won't\" : \"will not\",\n                \"wouldn't\" : \"would not\",\n                \"you'd\" : \"you would\",\n                \"you'll\" : \"you will\",\n                \"you're\" : \"you are\",\n                \"you've\" : \"you have\",\n                \"'re\": \" are\",\n                \"wasn't\": \"was not\",\n                \"we'll\":\" will\",\n                \"didn't\": \"did not\",\n                \"tryin'\":\"trying\"}","execution_count":10,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"26ypEMSLT3vq","trusted":true},"cell_type":"code","source":"mispellings, mispellings_re = _get_mispell(mispell_dict)","execution_count":11,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"7c_TchcCT3vs","trusted":true},"cell_type":"code","source":"def replace_typical_misspell(text):\n    def replace(match):\n        return mispellings[match.group(0)]\n\n    return mispellings_re.sub(replace, text)","execution_count":12,"outputs":[]},{"metadata":{"colab_type":"text","id":"CR8RjZmpT3vu"},"cell_type":"markdown","source":"### Loading Data"},{"metadata":{"colab":{},"colab_type":"code","id":"JZ2FDG8MT3vv","trusted":true},"cell_type":"code","source":"train_loc = '/kaggle/input/google-quest-challenge/train.csv'\ntest_loc= '/kaggle/input/google-quest-challenge/test.csv'\n\n# train_loc = 'google-quest-challenge/train.csv'\n# test_loc= 'google-quest-challenge/test.csv'\n\ntrain_df = pd.read_csv(train_loc)\ntest_df = pd.read_csv(test_loc)\n","execution_count":13,"outputs":[]},{"metadata":{"colab_type":"text","id":"BFcJKnZ9T3vy"},"cell_type":"markdown","source":"### Preprocessing"},{"metadata":{"colab":{},"colab_type":"code","id":"SonttmKnT3vy","trusted":true},"cell_type":"code","source":"train_df[\"question_body\"] = train_df[\"question_body\"].apply(clean_text)\ntrain_df[\"question_body\"] = train_df[\"question_body\"].apply(replace_typical_misspell)\n\ntrain_df[\"question_title\"] = train_df[\"question_title\"].apply(clean_text)\ntrain_df[\"question_title\"] = train_df[\"question_title\"].apply(replace_typical_misspell)\n\ntrain_df[\"category\"] = train_df[\"category\"].apply(clean_text)\ntrain_df[\"category\"] = train_df[\"category\"].apply(replace_typical_misspell)\n\ntrain_df[\"answer\"] = train_df[\"answer\"].apply(clean_text)\ntrain_df[\"answer\"] = train_df[\"answer\"].apply(replace_typical_misspell)\n\n\ntest_df[\"question_body\"] = test_df[\"question_body\"].apply(clean_text)\ntest_df[\"question_body\"] = test_df[\"question_body\"].apply(replace_typical_misspell)\n\ntest_df[\"question_title\"] = test_df[\"question_title\"].apply(clean_text)\ntest_df[\"question_title\"] = test_df[\"question_title\"].apply(replace_typical_misspell)\n\ntest_df[\"category\"] = test_df[\"category\"].apply(clean_text)\ntest_df[\"category\"] = test_df[\"category\"].apply(replace_typical_misspell)\n\ntest_df[\"answer\"] = test_df[\"answer\"].apply(clean_text)\ntest_df[\"answer\"] = test_df[\"answer\"].apply(replace_typical_misspell)","execution_count":14,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"I7vq6-EDT3v0","trusted":true},"cell_type":"code","source":"question_body = train_df['question_body']\nanswer = train_df['answer']\nquestion_title = train_df[\"question_title\"]\ncategory = train_df[\"category\"]\n\nquestion_body_test = test_df['question_body']\nanswer_test = test_df['answer']\nquestion_title_test = test_df[\"question_title\"]\ncategory_test = test_df[\"category\"]","execution_count":15,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"lmPgad44T3v2","trusted":true},"cell_type":"code","source":"target = train_df[train_df.columns[-30:]]","execution_count":16,"outputs":[]},{"metadata":{"colab_type":"text","id":"KRryeoqAT3v5"},"cell_type":"markdown","source":"### Creating Tokenziers"},{"metadata":{"colab":{},"colab_type":"code","id":"DJceUF8qT3v6","trusted":true},"cell_type":"code","source":"all_text = pd.concat([\n                    train_df['question_body'],\n                     train_df['answer'],\n                     test_df['question_body'],\n                     test_df['answer'],\n                     train_df[\"question_title\"],\n                     train_df[\"category\"],\n                     test_df[\"question_title\"],\n                     test_df[\"category\"]\n                    ])","execution_count":17,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":449,"status":"ok","timestamp":1578878325274,"user":{"displayName":"Emil Joswin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3fTReDoYuF-CGnvkmPxdSFOdnCwpwQNol9ghQ=s64","userId":"12652004406215465547"},"user_tz":300},"id":"vk_RL_VvT3v7","outputId":"0f8f7ca3-643f-4970-f268-5f16c0c061bd","trusted":true},"cell_type":"code","source":"len(train_df), len(test_df), 6079*4 + 476 * 4, len(all_text)","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"(6079, 476, 26220, 26220)"},"metadata":{}}]},{"metadata":{"colab":{},"colab_type":"code","id":"TivBnUFgT3v-","trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(num_words=1000000, lower=False,filters='')\n\ntokenizer.fit_on_texts(all_text)","execution_count":19,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":2967,"status":"ok","timestamp":1578878329103,"user":{"displayName":"Emil Joswin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3fTReDoYuF-CGnvkmPxdSFOdnCwpwQNol9ghQ=s64","userId":"12652004406215465547"},"user_tz":300},"id":"J1KJ9QHuT3wA","outputId":"df61c9d6-873c-4ce1-dab0-cd142f02b971","trusted":true},"cell_type":"code","source":"len(tokenizer.word_counts), tokenizer.word_index['the'], tokenizer.word_index['ABC']","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"(100498, 4, 8783)"},"metadata":{}}]},{"metadata":{"colab":{},"colab_type":"code","id":"Whxhk7tuT3wC","trusted":true},"cell_type":"code","source":"question_body = tokenizer.texts_to_sequences(question_body)\nanswer = tokenizer.texts_to_sequences(answer)\nquestion_title = tokenizer.texts_to_sequences(question_title)\ncategory = tokenizer.texts_to_sequences(category)\n\nquestion_body_test = tokenizer.texts_to_sequences(question_body_test)\nanswer_test = tokenizer.texts_to_sequences(answer_test)\nquestion_title_test = tokenizer.texts_to_sequences(question_title_test)\ncategory_test = tokenizer.texts_to_sequences(category_test)","execution_count":21,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":1544,"status":"ok","timestamp":1578878329420,"user":{"displayName":"Emil Joswin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3fTReDoYuF-CGnvkmPxdSFOdnCwpwQNol9ghQ=s64","userId":"12652004406215465547"},"user_tz":300},"id":"BzYwGh5XT3wE","outputId":"7f7ffd31-f575-40c9-f450-a0d42031a46a","trusted":true},"cell_type":"code","source":"len(question_body), len(question_body[0])","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"(6079, 174)"},"metadata":{}}]},{"metadata":{"colab":{},"colab_type":"code","id":"Eh5XnfXvT3wJ","trusted":true},"cell_type":"code","source":"vocab_size = len(tokenizer.word_index) + 1\nmaxlen = 245","execution_count":23,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"mVirIudhT3wM","trusted":true},"cell_type":"code","source":"question_body = pad_sequences(question_body, padding='post', maxlen=maxlen)\nanswer = pad_sequences(answer, padding='post', maxlen=maxlen)\nquestion_title = pad_sequences(question_title, padding='post', maxlen=maxlen)\ncategory = pad_sequences(category, padding='post', maxlen=maxlen)\n\n\nquestion_body_test = pad_sequences(question_body_test, padding='post', maxlen=maxlen)\nanswer_test = pad_sequences(answer_test, padding='post', maxlen=maxlen)\nquestion_title_test = pad_sequences(question_title_test, padding='post', maxlen=maxlen)\ncategory_test = pad_sequences(category_test, padding='post', maxlen=maxlen)","execution_count":24,"outputs":[]},{"metadata":{"colab_type":"text","id":"OWMWifotT3wO"},"cell_type":"markdown","source":"### Build embedding matrix for the full dataset\n\nGensim word vectors can be found here https://www.kaggle.com/iezepov/gensim-embeddings-dataset\n\nAll UNK tokens will be 0s. This is different from the NLP project, where the UNK tokens are the average of the matrix."},{"metadata":{"colab":{},"colab_type":"code","id":"YWyKvf9JT3wO","trusted":true},"cell_type":"code","source":"emb_size = 200\n\ndef build_matrix(word_index, path):\n    embedding_index = KeyedVectors.load(path, mmap='r')\n    embedding_matrix = np.zeros((len(word_index) + 1, emb_size))\n    for word, i in word_index.items():\n        for candidate in [word, word.lower()]:\n            if candidate in embedding_index:\n                embedding_matrix[i] = embedding_index[candidate]\n                break\n    return embedding_matrix","execution_count":25,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"colab_type":"code","executionInfo":{"elapsed":4812,"status":"ok","timestamp":1578878338420,"user":{"displayName":"Emil Joswin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3fTReDoYuF-CGnvkmPxdSFOdnCwpwQNol9ghQ=s64","userId":"12652004406215465547"},"user_tz":300},"id":"MK0uZLtXT3wQ","outputId":"4782009f-1c0f-4666-b153-717b1f40e1ae","trusted":true},"cell_type":"code","source":"# EMBEDDING_FILES = ['/Users/emiljoswin/study/playground/jupyter_notebooks/NLP/crawl-300d-2M.gensim', \n#                   '/Users/emiljoswin/study/playground/jupyter_notebooks/NLP/glove.840B.300d.gensim']\n\nEMBEDDING_FILES = ['/kaggle/input/gensim-word-embeddings/glove.twitter.27B.200d.gensim']\n\n# EMBEDDING_FILES = ['../../NLP/pre-trained-weights/gensim-embeddings-dataset/glove.twitter.27B.200d.gensim']\n\nembedding_index = KeyedVectors.load(EMBEDDING_FILES[0], mmap='r')\n# embedding_index = KeyedVectors.load(EMBEDDING_FILES[1], mmap='r')","execution_count":26,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"colab_type":"code","executionInfo":{"elapsed":8369,"status":"ok","timestamp":1578878342107,"user":{"displayName":"Emil Joswin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3fTReDoYuF-CGnvkmPxdSFOdnCwpwQNol9ghQ=s64","userId":"12652004406215465547"},"user_tz":300},"id":"8rIFw0osT3wS","outputId":"0ae00de4-3340-484f-d1e0-61b18d3297af","trusted":true},"cell_type":"code","source":"m1 = build_matrix(tokenizer.word_index, EMBEDDING_FILES[0])\n# m2 = build_matrix(tokenizer.word_index, EMBEDDING_FILES[1])\n# m1.shape, m2.shape, \nm1.shape","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"(100499, 200)"},"metadata":{}}]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":923,"status":"ok","timestamp":1578878342372,"user":{"displayName":"Emil Joswin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3fTReDoYuF-CGnvkmPxdSFOdnCwpwQNol9ghQ=s64","userId":"12652004406215465547"},"user_tz":300},"id":"_8QlZPaQT3wY","outputId":"8b2dfef8-3056-482a-954c-12626f3ea503","trusted":true},"cell_type":"code","source":"# embedding_matrix = np.concatenate([m1, m2], axis=-1)\n# embedding_matrix.shape\n\nembedding_matrix = m1\nembedding_matrix.shape","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"(100499, 200)"},"metadata":{}}]},{"metadata":{"colab_type":"text","id":"UenY-gXKCfgV"},"cell_type":"markdown","source":"# Train Test Split"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":1408,"status":"ok","timestamp":1578887787987,"user":{"displayName":"Emil Joswin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3fTReDoYuF-CGnvkmPxdSFOdnCwpwQNol9ghQ=s64","userId":"12652004406215465547"},"user_tz":300},"id":"ChjGCi33C39o","outputId":"0b2bd082-15fe-49d3-b5a2-82d66f514a18","trusted":true},"cell_type":"code","source":"X = concatenate([question_body, question_title, category, answer], 1)\nprint(X.shape)\nY = target.to_numpy()\nprint(Y.shape)\n\ntest_original = concatenate([question_body_test, question_title_test, category_test, answer_test], 1)\nprint(test_original.shape)","execution_count":102,"outputs":[{"output_type":"stream","text":"(6079, 980)\n(6079, 30)\n(476, 980)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"total = 6079\nval_size = 700\n\np = np.random.permutation(list(range(total)))\n\nval_idx = p[:val_size]\ntrain_idx = p[val_size:]\n\ntrain_x = tf.gather(X, train_idx)\ntrain_y = tf.gather(Y, train_idx)\n\nval_x = tf.gather(X, val_idx)\nval_y = tf.gather(Y, val_idx)\n\nprint(train_x.shape, train_y.shape, val_x.shape, val_y.shape)\n","execution_count":89,"outputs":[{"output_type":"stream","text":"(5379, 980) (5379, 30) (700, 980) (700, 30)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(val_idx)","execution_count":90,"outputs":[{"output_type":"stream","text":"[5738 2628 4041 3105  113 1266 2717 4256 4599 3825 2020  357 4728 5065\n 4583 5393 4743 2328 2363 1078 4845 3708 4059 3890  205 5384  160 4077\n 3074 2333 4647 6076 1914 3828  602 5914  839 1246 4060  999 5159 3412\n 2215 1709 1277 3585  369 4865 1427 4809 4390 5218 4910 1950 3421  673\n 1953 2168 4050 2230  293 3006 3817 5421 2442 3303 5578 4997 2391 3430\n 5243 3776 2154 1517 1178 4451 2309 2103 1474 1650 5440 2684 3703 1899\n 4097 4527 4963  218 4203 3294  112 1757 5889 4856 4630 5834 5184 5902\n 3496 4370 3820  647 2980 4498 1208 5056 3079   49 4068  284 5318 1652\n 2531 2254 1039 5681 5934 4300 4189 5663 1661 4192 5167 5612 5927 3612\n 3249 5383 5524 4986   15 3002  967  624  247 1570  200  135 4334 5217\n 1282 2222 5842 1225 4876 4895 3508  644 4628 2424 2337 5183   52    5\n  630 3730 2344 4170 4099 4941 2566 5207 4112 1692 3851 4756  747  149\n  907 5189  628 4979 4749 1342 3929 5106 3532 5066  152 6024 4205  772\n 3654 1784 4863 1059 3220  450 1399 2967 1365 3517 4100 1941 2960 5246\n 2807 1528 4649 5327 3746 2864 2517 2576 3911 3540 4923 2090 4532 1384\n   70 5893  379  506  260  944 4268 3468 3344  525  951 2325 2776 5728\n 6006  948 5163 1617 2087 4064  514 2023 4173 4333 3340 4947 2472 5029\n 2034 4988 2631  262 3892 3586 1799 1265  305 4103 2174 2541 4683   47\n 5898 1267 5751 5492 3656  816 4091 1839 4926 5897 1795 1933 2217 1139\n  936 3980 1586 5475 4057  538 5330 1003 6009 3842 5471 5620 3523 1256\n 6018 1628 2854 4735 2774   19  304 4075 2127 1021  685 5145  776 2818\n 4667 3035 3227 4478 4644 4967 5996 2236 5671 2137  385 2615 1793 1323\n 1402 3641  613 4699  360 3307 1243 2474  396 1807 4617 3628 4597 5045\n 2701 5337 5153 3917 2179 1491 5100 2284 5786 2660 1171 5892 4841  518\n 1539   97 2412 4056 3680 3450 1358 2119 1433 1665 1653 3678 5875 4538\n 4781 2827  290 3271  741  724 5693 2091 5837 3119 6027 1595 2252 1722\n   95 3939 3372 3360  807  977 1562 5138   59 4531 2189 4449 2820 2054\n 2559 3716 2184 3112 5717 5537  732 5186 3616 4525 4413 3758 6059 1457\n 1887 2452 3312  327 5629 5270 2563 6005 2876 2635 4475 3620  373 3991\n 3353 4795 5096 5244 6002 5369 4796 3595 5322 5294  101 2788 1938 2966\n  554  933 4014 1743 2965 2238 4462 5083 1999 2102 3278 1250 3536   99\n 5007 2958 3346 4668  533 4924 4215 2069 5732 2626 2052 1954 3100 4717\n  876 1347 5546 2512  937 1421 6031  219 3633 4663  971 4850 2909  850\n 1142 5250 4786 5696  119  961 5280 4184 1771  856 4987 6062 4039 3068\n 5525 5646   62 2297  575 1236 5288  670 2671 3322 2038 1037 4946 4741\n 1239 2754 5594 5257 5936 3884  429 1669 3286 1883 3896 2654 1732 2507\n 1229 2662 2036 4892 1262  744  657 1786 1470 3819 4664 2288 5625  184\n 2955  424 4357  487 5773 3907 3045 1935  649 2097  468 4800 1466 2270\n 4279 5511 1614 4632 4037 3088 2936  874 1783 2719 5694 1934  336 1747\n 4139  405 1373 1068  245 5497 2207 6068 1270  749 5478 3376 1134 5366\n 3027 5027 5839 3241  905 3921 3600 5279  461 4691 3607 5277 2453 2055\n 1683   14 4085 1383  692 3132 1547 1351 2062 4526 5263 4817 3463 5111\n 3030 4595 4767 3623 1053 4670 3265 3563 2656 1286 4399 1217 2935 1621\n  214 5487  635 4614 4854 4199 5743 1920 4066 4596 3564 1431 2690 4450\n 3136 4764  955 5436 1900 3978 1493 3488 2232 2557 2343  927 2760 2848\n 3492 1837 4299   31 4826 3877 3844 2629 3313 5005 5908 5575 2398   50\n  483 2928 1542  736 1326 5805  607  130 2310 5943 2292  717 1602 5706\n  299  195 4859 4624 1902 3928 4886 2487 3384 4996 3738  668 4019 5819\n 2124  374 1611 5292 4584 3366 4643 2247 6004 4709  980 2951 1175  860\n 1693 5700 4431 2305 3709 1530 2710 3781 4877 2495 5632 2761 1844 3436]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_x = tf.convert_to_tensor(val_x)\nval_y = tf.convert_to_tensor(val_y)\n\ntrain_x = tf.convert_to_tensor(train_x)\ntrain_y = tf.convert_to_tensor(train_y)","execution_count":91,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x.shape, train_y.shape, val_x.shape, val_y.shape","execution_count":92,"outputs":[{"output_type":"execute_result","execution_count":92,"data":{"text/plain":"(TensorShape([5379, 980]),\n TensorShape([5379, 30]),\n TensorShape([700, 980]),\n TensorShape([700, 30]))"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Evaluate"},{"metadata":{"colab":{},"colab_type":"code","id":"EWIA7hdbpcEZ","trusted":true},"cell_type":"code","source":"from scipy.stats import spearmanr\nimport math\n\ndef calculate_mean_spearman_co(a, b):\n    \"\"\"\n        Calculates spearmans correlation coefficient \n        https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient\n        \n        In the scipy implementation if you pass x and y and if one of them is composed of all same values,\n        then it returns nan. I am changing those nans to zeros\n    \"\"\"\n    # print(a.shape, b.shape, len(a.shape))\n    # print(a, b)\n    if len(a.shape) == 1:\n        return 0\n\n    if a.shape[0] is None and a.shape[1] is None:\n         return 0\n         \n    ans = [spearmanr(a[:, i], b[:, i])[0] for i in range(a.shape[1])]\n\n    ans = [0. if math.isnan(elem) else elem for elem in ans]\n    return np.mean(ans), ans","execution_count":93,"outputs":[]},{"metadata":{"colab_type":"text","id":"d_-i384iDTgz"},"cell_type":"markdown","source":"# Extras"},{"metadata":{"colab":{},"colab_type":"code","id":"U6Xe49SJDUfV","trusted":true},"cell_type":"code","source":"# LSTM_UNITS = 64\n# DENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\n# BATCH_SIZE = 128\n# EPOCHS = 10","execution_count":51,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"kG5WumZ7DXL-","trusted":true},"cell_type":"code","source":"# words = Input(shape=(None,))","execution_count":52,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"x1W2klM3DfXF","trusted":true},"cell_type":"code","source":"# x = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(words)\n# x = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(x)\n# x = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(x)\n\n# hidden = concatenate([\n#         GlobalMaxPooling1D()(x),\n#         GlobalAveragePooling1D()(x),\n#     ])\n\n# hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\n# hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])","execution_count":53,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"Q-z0nvBCDhxU","trusted":true},"cell_type":"code","source":"# result = Dense(30, activation='sigmoid')(hidden)","execution_count":54,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"wzJcTMZODkJ9","trusted":true},"cell_type":"code","source":"# model2 = Model(inputs=words, outputs=[result])\n# model2.compile(loss='mean_squared_error', optimizer='rmsprop',metrics=['mae'])","execution_count":55,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":605},"colab_type":"code","executionInfo":{"elapsed":2023,"status":"ok","timestamp":1578887993780,"user":{"displayName":"Emil Joswin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3fTReDoYuF-CGnvkmPxdSFOdnCwpwQNol9ghQ=s64","userId":"12652004406215465547"},"user_tz":300},"id":"RD9xp-VMDmS0","outputId":"a4d8ebbb-584b-4e72-ac86-7f6021ec0e11","trusted":true},"cell_type":"code","source":"# model2.summary()","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model2.fit(\n#             train_x, train_y,\n#             batch_size=256,\n#             epochs=20,\n#             verbose=1,\n#         )","execution_count":57,"outputs":[{"output_type":"stream","text":"Train on 5379 samples\nEpoch 1/20\n5379/5379 [==============================] - 11s 2ms/sample - loss: 0.0673 - mae: 0.1898\nEpoch 2/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0577 - mae: 0.1674\nEpoch 3/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0559 - mae: 0.1630\nEpoch 4/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0545 - mae: 0.1608\nEpoch 5/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0540 - mae: 0.1589\nEpoch 6/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0521 - mae: 0.1560\nEpoch 7/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0524 - mae: 0.1554\nEpoch 8/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0514 - mae: 0.1538\nEpoch 9/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0502 - mae: 0.1514\nEpoch 10/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0499 - mae: 0.1505\nEpoch 11/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0492 - mae: 0.1497\nEpoch 12/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0477 - mae: 0.1468\nEpoch 13/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0476 - mae: 0.1465\nEpoch 14/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0466 - mae: 0.1444\nEpoch 15/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0462 - mae: 0.1440\nEpoch 16/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0456 - mae: 0.1420\nEpoch 17/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0452 - mae: 0.1418\nEpoch 18/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0441 - mae: 0.1398\nEpoch 19/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0442 - mae: 0.1399\nEpoch 20/20\n5379/5379 [==============================] - 7s 1ms/sample - loss: 0.0432 - mae: 0.1386\n","name":"stdout"},{"output_type":"execute_result","execution_count":57,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f541f447198>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# val_predictions = model2.predict(val_x)\n# m, _ = calculate_mean_spearman_co(val_predictions, val_y)\n# print(\"val_spearman\", m)","execution_count":58,"outputs":[{"output_type":"stream","text":"val_spearman 0.2998429770872825\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Model as a class"},{"metadata":{"trusted":true},"cell_type":"code","source":"LSTM_UNITS = 64\nDENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\nBATCH_SIZE = 128\nEPOCHS = 10\nOUTPUT_CLASSES = 30","execution_count":94,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MyModel(models.Model):\n    def __init__(self, embedding_matrix):\n        super(MyModel, self).__init__()\n        self.emb = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)\n        self.b1 = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))\n        self.b2 = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))\n#         self.attn_weight = tf.Variable(tf.random.normal((LSTM_UNITS*2, 1)))\n        self.g1 = GlobalMaxPooling1D()\n        self.g2 = GlobalAveragePooling1D()\n        \n        self.d1 = Dense(DENSE_HIDDEN_UNITS, activation='relu')\n        self.d2 = Dense(DENSE_HIDDEN_UNITS, activation='relu')\n        self.linear = Dense(OUTPUT_CLASSES, activation='sigmoid')\n        \n    def attn(self, inputs):\n        \"\"\"\n            inputs: [bsz x 980 x LSTM_UNITS*2]\n            output: [bsz x LSTM_UNITS]\n        \"\"\"\n        \n        # (1 x 128) (bsz x seq x 128 )T  => (2 x seq)\n        check = tf.einsum('ij,kjm->kim',\n                          tf.transpose(self.attn_weight), \n                          tf.transpose(inputs, [0, 2, 1])) # (bsz x 1 x 980) - a score for each time step\n        \n        check = tf.squeeze(check) # (bsz x 980)\n        check = tf.nn.softmax(check, axis=1) # attention weight (bsz x 980)\n        \n        #(bsz x seq x 128)T (bsz x seq) => (bsz x 128)\n        check = tf.einsum('ijk,ki->ij', \n                          tf.transpose(inputs, [0, 2, 1]), \n                          tf.transpose(check) ) # (bsz x LSTM_UNITS) - best of each 980 time-steps\n        \n        return check\n\n        \n        \n    def call(self, inputs):\n        x = self.emb(inputs)\n        x = self.b1(x)\n        x = self.b2(x)\n#         x1 = self.attn(x) # (bsz x LSTM_UNITS*2)\n#         x2 = self.attn(x)\n        x = concatenate([self.g1(x), self.g2(x)])\n        \n        x = add([x, self.d1(x)])\n        x = add([x, self.d2(x)])\n        x = self.linear(x)\n        return x","execution_count":95,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model3 = MyModel(embedding_matrix)","execution_count":96,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# out = model3(train_x[0:2, :])","execution_count":97,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# out.shape","execution_count":98,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model3.compile(loss='mean_squared_error', optimizer='rmsprop',metrics=['mae'])","execution_count":99,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# NOTE: READ THIS\n# ```````````````\n# This is not real cross-validation. I am actually trying to see at what epoch number is the validation \n# Spearman score starting to decrease. So, k here is just the iteration number.\n# I chose this method because each time, I will be validating it on a different random sample. A fixed sample\n# is not picked because, I am not able to come up with a good validation dataset.\n\ndef train(model, k, X, Y, bsz=256, epochs=10):\n    if k < 2:\n        k = 2\n    print(f'Doing {k}-Fold CV, bsz: {bsz}, epochs: {epochs}')\n    kf = KFold(n_splits=k)\n    \n    train_scores = []\n    val_scores = []\n    for i, (train_idx, val_idx) in enumerate(kf.split(X)):\n        train_x = tf.gather(X, train_idx)\n        train_y = tf.gather(Y, train_idx)\n\n        val_x = tf.gather(X, val_idx)\n        val_y = tf.gather(Y, val_idx)\n        \n        print(f'Running the fold: {i+1}')\n        model.fit(\n            train_x, train_y,\n            batch_size=256,\n            epochs=20,\n            verbose=1,\n        )\n        \n        train_predictions = model.predict(train_x)\n        m1, _ = calculate_mean_spearman_co(train_predictions, train_y)        \n        \n        val_predictions = model.predict(val_x)\n        m2, _ = calculate_mean_spearman_co(val_predictions, val_y)\n        \n        train_scores.append(m1)\n        val_scores.append(m2)\n        print(f'Train score: {m2}')      \n        print(f'Validation score: {m1}')  \n        return train_scores, val_scores","execution_count":100,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train(model3, 10, X, Y)","execution_count":81,"outputs":[{"output_type":"stream","text":"Doing 10-Fold CV\nRunning the fold: 0\nTrain on 5471 samples\nEpoch 1/20\n5471/5471 [==============================] - 14s 2ms/sample - loss: 0.0703 - mae: 0.1960\nEpoch 2/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0571 - mae: 0.1675\nEpoch 3/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0549 - mae: 0.1624\nEpoch 4/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0536 - mae: 0.1592\nEpoch 5/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0528 - mae: 0.1572\nEpoch 6/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0520 - mae: 0.1555\nEpoch 7/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0510 - mae: 0.1534\nEpoch 8/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0499 - mae: 0.1516\nEpoch 9/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0494 - mae: 0.1502\nEpoch 10/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0484 - mae: 0.1483\nEpoch 11/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0472 - mae: 0.1467\nEpoch 12/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0466 - mae: 0.1454\nEpoch 13/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0458 - mae: 0.1438\nEpoch 14/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0450 - mae: 0.1422\nEpoch 15/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0443 - mae: 0.1406\nEpoch 16/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0439 - mae: 0.1396\nEpoch 17/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0431 - mae: 0.1386\nEpoch 18/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0424 - mae: 0.1374\nEpoch 19/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0419 - mae: 0.1362\nEpoch 20/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0415 - mae: 0.1352\nValidation score: 0.31880212331226343\nRunning the fold: 1\nTrain on 5471 samples\nEpoch 1/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0412 - mae: 0.1346\nEpoch 2/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0405 - mae: 0.1336\nEpoch 3/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0402 - mae: 0.1327\nEpoch 4/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0398 - mae: 0.1319\nEpoch 5/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0389 - mae: 0.1302\nEpoch 6/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0384 - mae: 0.1291\nEpoch 7/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0382 - mae: 0.1286\nEpoch 8/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0371 - mae: 0.1270\nEpoch 9/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0371 - mae: 0.1264\nEpoch 10/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0369 - mae: 0.1258\nEpoch 11/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0360 - mae: 0.1248\nEpoch 12/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0357 - mae: 0.1237\nEpoch 13/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0350 - mae: 0.1228\nEpoch 14/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0346 - mae: 0.1219\nEpoch 15/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0345 - mae: 0.1213\nEpoch 16/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0335 - mae: 0.1195\nEpoch 17/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0334 - mae: 0.1195\nEpoch 18/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0329 - mae: 0.1186\nEpoch 19/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0324 - mae: 0.1176\nEpoch 20/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0320 - mae: 0.1165\nValidation score: 0.3704563115272259\nRunning the fold: 2\nTrain on 5471 samples\nEpoch 1/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0326 - mae: 0.1175\nEpoch 2/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0322 - mae: 0.1169\nEpoch 3/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0320 - mae: 0.1163\nEpoch 4/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0314 - mae: 0.1152\nEpoch 5/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0308 - mae: 0.1140\nEpoch 6/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0306 - mae: 0.1136\nEpoch 7/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0300 - mae: 0.1125\nEpoch 8/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0296 - mae: 0.1117\nEpoch 9/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0293 - mae: 0.1111\nEpoch 10/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0288 - mae: 0.1098\nEpoch 11/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0287 - mae: 0.1096\nEpoch 12/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0283 - mae: 0.1089\nEpoch 13/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0273 - mae: 0.1071\nEpoch 14/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0277 - mae: 0.1072\nEpoch 15/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0274 - mae: 0.1069\nEpoch 16/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0266 - mae: 0.1052\nEpoch 17/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0265 - mae: 0.1049\nEpoch 18/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0256 - mae: 0.1033\nEpoch 19/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0261 - mae: 0.1039\nEpoch 20/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0254 - mae: 0.1027\nValidation score: 0.4250606896431583\nRunning the fold: 3\nTrain on 5471 samples\nEpoch 1/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0259 - mae: 0.1033\nEpoch 2/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0260 - mae: 0.1036\nEpoch 3/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0254 - mae: 0.1025\nEpoch 4/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0253 - mae: 0.1020\nEpoch 5/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0247 - mae: 0.1010\nEpoch 6/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0242 - mae: 0.1001\nEpoch 7/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0238 - mae: 0.0987\nEpoch 8/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0242 - mae: 0.0999\nEpoch 9/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0235 - mae: 0.0983\nEpoch 10/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0231 - mae: 0.0976\nEpoch 11/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0230 - mae: 0.0971\nEpoch 12/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0228 - mae: 0.0966\nEpoch 13/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0219 - mae: 0.0951\nEpoch 14/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0226 - mae: 0.0960\nEpoch 15/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0218 - mae: 0.0947\nEpoch 16/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0219 - mae: 0.0944\nEpoch 17/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0215 - mae: 0.0937\nEpoch 18/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0207 - mae: 0.0924\nEpoch 19/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0209 - mae: 0.0924\nEpoch 20/20\n","name":"stdout"},{"output_type":"stream","text":"5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0207 - mae: 0.0920\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n  c /= stddev[:, None]\n/opt/conda/lib/python3.6/site-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n  c /= stddev[None, :]\n/opt/conda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in greater\n  return (a < x) & (x < b)\n/opt/conda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in less\n  return (a < x) & (x < b)\n/opt/conda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1892: RuntimeWarning: invalid value encountered in less_equal\n  cond2 = cond0 & (x <= _a)\n","name":"stderr"},{"output_type":"stream","text":"Validation score: 0.45867898897999837\nRunning the fold: 4\nTrain on 5471 samples\nEpoch 1/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0215 - mae: 0.0932\nEpoch 2/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0215 - mae: 0.0936\nEpoch 3/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0206 - mae: 0.0917\nEpoch 4/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0206 - mae: 0.0916\nEpoch 5/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0205 - mae: 0.0911\nEpoch 6/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0198 - mae: 0.0900\nEpoch 7/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0202 - mae: 0.0904\nEpoch 8/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0195 - mae: 0.0892\nEpoch 9/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0196 - mae: 0.0892\nEpoch 10/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0190 - mae: 0.0879\nEpoch 11/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0189 - mae: 0.0879\nEpoch 12/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0189 - mae: 0.0875\nEpoch 13/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0186 - mae: 0.0871\nEpoch 14/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0183 - mae: 0.0862\nEpoch 15/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0183 - mae: 0.0861\nEpoch 16/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0180 - mae: 0.0853\nEpoch 17/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0177 - mae: 0.0847\nEpoch 18/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0177 - mae: 0.0848\nEpoch 19/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0175 - mae: 0.0841\nEpoch 20/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0173 - mae: 0.0838\nValidation score: 0.5126157691683644\nRunning the fold: 5\nTrain on 5471 samples\nEpoch 1/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0183 - mae: 0.0856\nEpoch 2/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0174 - mae: 0.0838\nEpoch 3/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0177 - mae: 0.0846\nEpoch 4/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0172 - mae: 0.0833\nEpoch 5/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0172 - mae: 0.0832\nEpoch 6/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0166 - mae: 0.0819\nEpoch 7/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0167 - mae: 0.0819\nEpoch 8/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0163 - mae: 0.0814\nEpoch 9/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0163 - mae: 0.0812\nEpoch 10/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0162 - mae: 0.0809\nEpoch 11/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0157 - mae: 0.0800\nEpoch 12/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0160 - mae: 0.0802\nEpoch 13/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0158 - mae: 0.0798\nEpoch 14/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0156 - mae: 0.0793\nEpoch 15/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0150 - mae: 0.0782\nEpoch 16/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0153 - mae: 0.0785\nEpoch 17/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0153 - mae: 0.0787\nEpoch 18/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0149 - mae: 0.0775\nEpoch 19/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0149 - mae: 0.0774\nEpoch 20/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0144 - mae: 0.0763\nValidation score: 0.5405676030813021\nRunning the fold: 6\nTrain on 5471 samples\nEpoch 1/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0157 - mae: 0.0790\nEpoch 2/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0150 - mae: 0.0777\nEpoch 3/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0152 - mae: 0.0781\nEpoch 4/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0147 - mae: 0.0768\nEpoch 5/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0148 - mae: 0.0770\nEpoch 6/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0143 - mae: 0.0759\nEpoch 7/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0141 - mae: 0.0755\nEpoch 8/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0142 - mae: 0.0755\nEpoch 9/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0140 - mae: 0.0752\nEpoch 10/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0140 - mae: 0.0751\nEpoch 11/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0138 - mae: 0.0747\nEpoch 12/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0134 - mae: 0.0735\nEpoch 13/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0133 - mae: 0.0731\nEpoch 14/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0137 - mae: 0.0742\nEpoch 15/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0133 - mae: 0.0732\nEpoch 16/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0130 - mae: 0.0725\nEpoch 17/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0132 - mae: 0.0729\nEpoch 18/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0130 - mae: 0.0723\nEpoch 19/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0127 - mae: 0.0716\nEpoch 20/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0129 - mae: 0.0718\nValidation score: 0.5577503224358185\nRunning the fold: 7\nTrain on 5471 samples\nEpoch 1/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0132 - mae: 0.0727\nEpoch 2/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0132 - mae: 0.0727\nEpoch 3/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0129 - mae: 0.0720\nEpoch 4/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0128 - mae: 0.0715\nEpoch 5/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0124 - mae: 0.0706\nEpoch 6/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0126 - mae: 0.0710\nEpoch 7/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0121 - mae: 0.0699\nEpoch 8/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0124 - mae: 0.0704\nEpoch 9/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0121 - mae: 0.0698\nEpoch 10/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0120 - mae: 0.0697\nEpoch 11/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0119 - mae: 0.0690\nEpoch 12/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0116 - mae: 0.0683\nEpoch 13/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0119 - mae: 0.0692\nEpoch 14/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0116 - mae: 0.0682\nEpoch 15/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0115 - mae: 0.0680\nEpoch 16/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0115 - mae: 0.0681\nEpoch 17/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0111 - mae: 0.0669\nEpoch 18/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0111 - mae: 0.0667\nEpoch 19/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0112 - mae: 0.0670\nEpoch 20/20\n","name":"stdout"},{"output_type":"stream","text":"5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0112 - mae: 0.0669\nValidation score: 0.5800397863628175\nRunning the fold: 8\nTrain on 5471 samples\nEpoch 1/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0116 - mae: 0.0679\nEpoch 2/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0115 - mae: 0.0676\nEpoch 3/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0114 - mae: 0.0676\nEpoch 4/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0112 - mae: 0.0666\nEpoch 5/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0109 - mae: 0.0660\nEpoch 6/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0111 - mae: 0.0663\nEpoch 7/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0109 - mae: 0.0660\nEpoch 8/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0108 - mae: 0.0658\nEpoch 9/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0107 - mae: 0.0655\nEpoch 10/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0106 - mae: 0.0651\nEpoch 11/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0107 - mae: 0.0653\nEpoch 12/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0104 - mae: 0.0645\nEpoch 13/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0103 - mae: 0.0643\nEpoch 14/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0104 - mae: 0.0643\nEpoch 15/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0101 - mae: 0.0635\nEpoch 16/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0102 - mae: 0.0639\nEpoch 17/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0099 - mae: 0.0633\nEpoch 18/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0100 - mae: 0.0631\nEpoch 19/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0099 - mae: 0.0633\nEpoch 20/20\n5471/5471 [==============================] - 7s 1ms/sample - loss: 0.0098 - mae: 0.0625\nValidation score: 0.6035710655705786\nRunning the fold: 9\nTrain on 5472 samples\nEpoch 1/20\n5472/5472 [==============================] - 7s 1ms/sample - loss: 0.0105 - mae: 0.0645\nEpoch 2/20\n5472/5472 [==============================] - 7s 1ms/sample - loss: 0.0101 - mae: 0.0635\nEpoch 3/20\n5472/5472 [==============================] - 7s 1ms/sample - loss: 0.0100 - mae: 0.0631\nEpoch 4/20\n5472/5472 [==============================] - 7s 1ms/sample - loss: 0.0098 - mae: 0.0627\nEpoch 5/20\n5472/5472 [==============================] - 7s 1ms/sample - loss: 0.0100 - mae: 0.0629\nEpoch 6/20\n5472/5472 [==============================] - 7s 1ms/sample - loss: 0.0096 - mae: 0.0621\nEpoch 7/20\n5472/5472 [==============================] - 7s 1ms/sample - loss: 0.0097 - mae: 0.0622\nEpoch 8/20\n5472/5472 [==============================] - 7s 1ms/sample - loss: 0.0096 - mae: 0.0619\nEpoch 9/20\n5472/5472 [==============================] - 7s 1ms/sample - loss: 0.0094 - mae: 0.0612\nEpoch 10/20\n5472/5472 [==============================] - 7s 1ms/sample - loss: 0.0094 - mae: 0.0613\nEpoch 11/20\n5472/5472 [==============================] - 7s 1ms/sample - loss: 0.0095 - mae: 0.0618\nEpoch 12/20\n5472/5472 [==============================] - 7s 1ms/sample - loss: 0.0092 - mae: 0.0607\nEpoch 13/20\n5472/5472 [==============================] - 7s 1ms/sample - loss: 0.0094 - mae: 0.0614\nEpoch 14/20\n5472/5472 [==============================] - 7s 1ms/sample - loss: 0.0091 - mae: 0.0602\nEpoch 15/20\n5472/5472 [==============================] - 7s 1ms/sample - loss: 0.0091 - mae: 0.0603\nEpoch 16/20\n5472/5472 [==============================] - 7s 1ms/sample - loss: 0.0089 - mae: 0.0596\nEpoch 17/20\n5472/5472 [==============================] - 7s 1ms/sample - loss: 0.0090 - mae: 0.0603\nEpoch 18/20\n5472/5472 [==============================] - 7s 1ms/sample - loss: 0.0089 - mae: 0.0599\nEpoch 19/20\n5472/5472 [==============================] - 7s 1ms/sample - loss: 0.0088 - mae: 0.0593\nEpoch 20/20\n5472/5472 [==============================] - 7s 1ms/sample - loss: 0.0087 - mae: 0.0593\nValidation score: 0.6078624008428256\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n  c /= stddev[:, None]\n/opt/conda/lib/python3.6/site-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n  c /= stddev[None, :]\n/opt/conda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in greater\n  return (a < x) & (x < b)\n/opt/conda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in less\n  return (a < x) & (x < b)\n/opt/conda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1892: RuntimeWarning: invalid value encountered in less_equal\n  cond2 = cond0 & (x <= _a)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Just verifying the train-prediction spearman score\n# all_predictions = model3.predict(X)\n# m, _ = calculate_mean_spearman_co(all_predictions, Y)\n# print(m)","execution_count":83,"outputs":[{"output_type":"stream","text":"0.6387985168162696\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(X), type(Y)","execution_count":101,"outputs":[{"output_type":"execute_result","execution_count":101,"data":{"text/plain":"(tensorflow.python.framework.ops.EagerTensor, numpy.ndarray)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# After computing the total epoch number\nmodel3.fit(\n            X, tf.convert_to_tensor(Y),\n            batch_size=256,\n            epochs=100,\n            verbose=1,\n        )","execution_count":105,"outputs":[{"output_type":"stream","text":"Train on 6079 samples\nEpoch 1/100\n6079/6079 [==============================] - 15s 2ms/sample - loss: 0.0662 - mae: 0.1873\nEpoch 2/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0561 - mae: 0.1651\nEpoch 3/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0543 - mae: 0.1608\nEpoch 4/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0531 - mae: 0.1576\nEpoch 5/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0520 - mae: 0.1550\nEpoch 6/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0508 - mae: 0.1534\nEpoch 7/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0498 - mae: 0.1512\nEpoch 8/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0491 - mae: 0.1497\nEpoch 9/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0482 - mae: 0.1478\nEpoch 10/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0472 - mae: 0.1461\nEpoch 11/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0463 - mae: 0.1443\nEpoch 12/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0455 - mae: 0.1430\nEpoch 13/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0449 - mae: 0.1418\nEpoch 14/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0443 - mae: 0.1405\nEpoch 15/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0436 - mae: 0.1393\nEpoch 16/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0428 - mae: 0.1377\nEpoch 17/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0423 - mae: 0.1368\nEpoch 18/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0417 - mae: 0.1354\nEpoch 19/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0411 - mae: 0.1346\nEpoch 20/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0408 - mae: 0.1336\nEpoch 21/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0400 - mae: 0.1323\nEpoch 22/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0396 - mae: 0.1313\nEpoch 23/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0391 - mae: 0.1305\nEpoch 24/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0385 - mae: 0.1294\nEpoch 25/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0378 - mae: 0.1279\nEpoch 26/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0374 - mae: 0.1273\nEpoch 27/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0370 - mae: 0.1264\nEpoch 28/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0367 - mae: 0.1255\nEpoch 29/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0362 - mae: 0.1249\nEpoch 30/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0355 - mae: 0.1235\nEpoch 31/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0352 - mae: 0.1227\nEpoch 32/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0347 - mae: 0.1218\nEpoch 33/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0342 - mae: 0.1208\nEpoch 34/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0337 - mae: 0.1199\nEpoch 35/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0334 - mae: 0.1192\nEpoch 36/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0328 - mae: 0.1180\nEpoch 37/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0326 - mae: 0.1177\nEpoch 38/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0322 - mae: 0.1167\nEpoch 39/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0317 - mae: 0.1158\nEpoch 40/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0312 - mae: 0.1147\nEpoch 41/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0310 - mae: 0.1145\nEpoch 42/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0307 - mae: 0.1136\nEpoch 43/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0302 - mae: 0.1126\nEpoch 44/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0297 - mae: 0.1117\nEpoch 45/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0290 - mae: 0.1106\nEpoch 46/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0291 - mae: 0.1103\nEpoch 47/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0286 - mae: 0.1094\nEpoch 48/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0283 - mae: 0.1086\nEpoch 49/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0280 - mae: 0.1081\nEpoch 50/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0276 - mae: 0.1072\nEpoch 51/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0271 - mae: 0.1064\nEpoch 52/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0272 - mae: 0.1061\nEpoch 53/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0262 - mae: 0.1046\nEpoch 54/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0264 - mae: 0.1047\nEpoch 55/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0261 - mae: 0.1039\nEpoch 56/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0257 - mae: 0.1034\nEpoch 57/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0254 - mae: 0.1026\nEpoch 58/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0250 - mae: 0.1019\nEpoch 59/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0248 - mae: 0.1016\nEpoch 60/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0243 - mae: 0.1003\nEpoch 61/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0242 - mae: 0.0999\nEpoch 62/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0240 - mae: 0.0998\nEpoch 63/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0237 - mae: 0.0988\nEpoch 64/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0232 - mae: 0.0979\nEpoch 65/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0231 - mae: 0.0978\nEpoch 66/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0228 - mae: 0.0971\nEpoch 67/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0225 - mae: 0.0964\nEpoch 68/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0222 - mae: 0.0955\nEpoch 69/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0222 - mae: 0.0957\nEpoch 70/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0219 - mae: 0.0948\nEpoch 71/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0213 - mae: 0.0936\nEpoch 72/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0216 - mae: 0.0941\nEpoch 73/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0213 - mae: 0.0934\nEpoch 74/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0208 - mae: 0.0922\nEpoch 75/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0207 - mae: 0.0921\nEpoch 76/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0206 - mae: 0.0921\nEpoch 77/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0203 - mae: 0.0913\nEpoch 78/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0199 - mae: 0.0904\nEpoch 79/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0199 - mae: 0.0904\nEpoch 80/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0196 - mae: 0.0896\nEpoch 81/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0195 - mae: 0.0890\n","name":"stdout"},{"output_type":"stream","text":"Epoch 82/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0191 - mae: 0.0884\nEpoch 83/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0188 - mae: 0.0878\nEpoch 84/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0189 - mae: 0.0877\nEpoch 85/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0185 - mae: 0.0869\nEpoch 86/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0186 - mae: 0.0872\nEpoch 87/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0184 - mae: 0.0867\nEpoch 88/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0179 - mae: 0.0855\nEpoch 89/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0180 - mae: 0.0858\nEpoch 90/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0177 - mae: 0.0847\nEpoch 91/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0177 - mae: 0.0852\nEpoch 92/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0171 - mae: 0.0835\nEpoch 93/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0174 - mae: 0.0841\nEpoch 94/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0169 - mae: 0.0832\nEpoch 95/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0172 - mae: 0.0835\nEpoch 96/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0167 - mae: 0.0823\nEpoch 97/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0167 - mae: 0.0822\nEpoch 98/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0164 - mae: 0.0816\nEpoch 99/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0165 - mae: 0.0815\nEpoch 100/100\n6079/6079 [==============================] - 8s 1ms/sample - loss: 0.0159 - mae: 0.0807\n","name":"stdout"},{"output_type":"execute_result","execution_count":105,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f54029e6a58>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# val_predictions = model3.predict(val_x)\n# m, _ = calculate_mean_spearman_co(val_predictions, val_y)\n# print(\"val_spearman\", m) #0.3237 => gave 0.289","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Saving the predictions"},{"metadata":{"trusted":false},"cell_type":"code","source":"predictions = model3.predict(test_original)\nprint(predictions.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"target_cols = ['question_asker_intent_understanding',\n       'question_body_critical', 'question_conversational',\n       'question_expect_short_answer', 'question_fact_seeking',\n       'question_has_commonly_accepted_answer',\n       'question_interestingness_others', 'question_interestingness_self',\n       'question_multi_intent', 'question_not_really_a_question',\n       'question_opinion_seeking', 'question_type_choice',\n       'question_type_compare', 'question_type_consequence',\n       'question_type_definition', 'question_type_entity',\n       'question_type_instructions', 'question_type_procedure',\n       'question_type_reason_explanation', 'question_type_spelling',\n       'question_well_written', 'answer_helpful',\n       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n       'answer_satisfaction', 'answer_type_instructions',\n       'answer_type_procedure', 'answer_type_reason_explanation',\n       'answer_well_written']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"loc = '/kaggle/input/google-quest-challenge/sample_submission.csv'\n# loc = 'google-quest-challenge/sample_submission.csv'\nsub = pd.read_csv(loc)\n\nfor col_index, col in enumerate(target_cols):\n    sub[col] = predictions[:, col_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sub.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"1-notebook.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":1}