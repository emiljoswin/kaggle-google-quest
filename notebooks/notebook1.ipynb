{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/emiljoswin/study/Kaggle/Google Quest\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.run_this_cell {display: block !important;} </style"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "display(HTML(\"<style>.run_this_cell {display: block !important;} </style\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, concatenate, LSTM, Bidirectional, Embedding, add, Dense\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Tuple, Any\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(x):\n",
    "\n",
    "    x = str(x)\n",
    "    for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^`{|}~' + '“”’':\n",
    "        x = x.replace(punct, f' {punct}')\n",
    "   \n",
    "    for punct in '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n“”’\\'∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—_':\n",
    "        x = x.replace(punct, f' {punct}')\n",
    " \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    return mispell_dict, mispell_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mispell_dict = {\"usepackage\" : \"use package\",\n",
    "                'instrumentsettingsid':'instrumental settings id',\n",
    "                'RippleShaderProgram' : 'ripple shader program',\n",
    "                'ShaderProgramConstants':'shader program constants',\n",
    "                'storedElements':'stored elements',\n",
    "                'stackSize' : 'stack size',\n",
    "                '_':' '\n",
    "\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mispellings, mispellings_re = _get_mispell(mispell_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_typical_misspell(text):\n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "\n",
    "    return mispellings_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loc = '/kaggle/input/google-quest-challenge/train.csv'\n",
    "# test_loc= '/kaggle/input/google-quest-challenge/test.csv'\n",
    "\n",
    "train_loc = 'google-quest-challenge/train.csv'\n",
    "test_loc= 'google-quest-challenge/test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_loc)\n",
    "test_df = pd.read_csv(test_loc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"question_body\"] = train_df[\"question_body\"].apply(clean_text)\n",
    "train_df[\"question_body\"] = train_df[\"question_body\"].apply(replace_typical_misspell)\n",
    "\n",
    "train_df[\"question_title\"] = train_df[\"question_title\"].apply(clean_text)\n",
    "train_df[\"question_title\"] = train_df[\"question_title\"].apply(replace_typical_misspell)\n",
    "\n",
    "train_df[\"category\"] = train_df[\"category\"].apply(clean_text)\n",
    "train_df[\"category\"] = train_df[\"category\"].apply(replace_typical_misspell)\n",
    "\n",
    "train_df[\"answer\"] = train_df[\"answer\"].apply(clean_text)\n",
    "train_df[\"answer\"] = train_df[\"answer\"].apply(replace_typical_misspell)\n",
    "\n",
    "\n",
    "test_df[\"question_body\"] = test_df[\"question_body\"].apply(clean_text)\n",
    "test_df[\"question_body\"] = test_df[\"question_body\"].apply(replace_typical_misspell)\n",
    "\n",
    "test_df[\"question_title\"] = test_df[\"question_title\"].apply(clean_text)\n",
    "test_df[\"question_title\"] = test_df[\"question_title\"].apply(replace_typical_misspell)\n",
    "\n",
    "test_df[\"category\"] = test_df[\"category\"].apply(clean_text)\n",
    "test_df[\"category\"] = test_df[\"category\"].apply(replace_typical_misspell)\n",
    "\n",
    "test_df[\"answer\"] = test_df[\"answer\"].apply(clean_text)\n",
    "test_df[\"answer\"] = test_df[\"answer\"].apply(replace_typical_misspell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_body = train_df['question_body']\n",
    "answer = train_df['answer']\n",
    "question_title = train_df[\"question_title\"]\n",
    "category = train_df[\"category\"]\n",
    "\n",
    "question_body_test = test_df['question_body']\n",
    "answer_test = test_df['answer']\n",
    "question_title_test = test_df[\"question_title\"]\n",
    "category_test = test_df[\"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_df[train_df.columns[-30:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Tokenziers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = pd.concat([\n",
    "                    train_df['question_body'],\n",
    "                     train_df['answer'],\n",
    "                     test_df['question_body'],\n",
    "                     test_df['answer'],\n",
    "                     train_df[\"question_title\"],\n",
    "                     train_df[\"category\"],\n",
    "                     test_df[\"question_title\"],\n",
    "                     test_df[\"category\"]\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6079, 476, 26220, 26220)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(test_df), 6079*4 + 476 * 4, len(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=1000000, lower=False,filters='')\n",
    "\n",
    "tokenizer.fit_on_texts(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100533, 4, 8784)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_counts), tokenizer.word_index['the'], tokenizer.word_index['ABC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_body = tokenizer.texts_to_sequences(question_body)\n",
    "answer = tokenizer.texts_to_sequences(answer)\n",
    "question_title = tokenizer.texts_to_sequences(question_title)\n",
    "category = tokenizer.texts_to_sequences(category)\n",
    "\n",
    "question_body_test = tokenizer.texts_to_sequences(question_body_test)\n",
    "answer_test = tokenizer.texts_to_sequences(answer_test)\n",
    "question_title_test = tokenizer.texts_to_sequences(question_title_test)\n",
    "category_test = tokenizer.texts_to_sequences(category_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6079, 174)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(question_body), len(question_body[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "maxlen = 245"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_body = pad_sequences(question_body, padding='post', maxlen=maxlen)\n",
    "answer = pad_sequences(answer, padding='post', maxlen=maxlen)\n",
    "question_title = pad_sequences(question_title, padding='post', maxlen=maxlen)\n",
    "category = pad_sequences(category, padding='post', maxlen=maxlen)\n",
    "\n",
    "\n",
    "question_body_test = pad_sequences(question_body_test, padding='post', maxlen=maxlen)\n",
    "answer_test = pad_sequences(answer_test, padding='post', maxlen=maxlen)\n",
    "question_title_test = pad_sequences(question_title_test, padding='post', maxlen=maxlen)\n",
    "category_test = pad_sequences(category_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build embedding matrix for the full dataset\n",
    "\n",
    "Gensim word vectors can be found here https://www.kaggle.com/iezepov/gensim-embeddings-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix(word_index, path):\n",
    "    embedding_index = KeyedVectors.load(path, mmap='r')\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "    for word, i in word_index.items():\n",
    "        for candidate in [word, word.lower()]:\n",
    "            if candidate in embedding_index:\n",
    "                embedding_matrix[i] = embedding_index[candidate]\n",
    "                break\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILES = ['/Users/emiljoswin/study/playground/jupyter_notebooks/NLP/crawl-300d-2M.gensim', \n",
    "                  '/Users/emiljoswin/study/playground/jupyter_notebooks/NLP/glove.840B.300d.gensim']\n",
    "\n",
    "embedding_index = KeyedVectors.load(EMBEDDING_FILES[0], mmap='r')\n",
    "embedding_index = KeyedVectors.load(EMBEDDING_FILES[1], mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100534, 300), (100534, 300))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = build_matrix(tokenizer.word_index, EMBEDDING_FILES[0])\n",
    "m2 = build_matrix(tokenizer.word_index, EMBEDDING_FILES[1])\n",
    "m1.shape, m2.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100534, 600)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = np.concatenate([m1, m2], axis=-1)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_UNITS = 64\n",
    "DENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1 = Input(shape=(None,))\n",
    "inp2 = Input(shape=(None,))\n",
    "inp3 = Input(shape=(None,))\n",
    "inp4 = Input(shape=(None,))\n",
    "words = concatenate([inp1,inp2,inp3,inp4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(words)\n",
    "x = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(x)\n",
    "\n",
    "hidden = concatenate([\n",
    "        GlobalMaxPooling1D()(x),\n",
    "        GlobalAveragePooling1D()(x),\n",
    "    ])\n",
    "\n",
    "hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\n",
    "hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Dense(30, activation='sigmoid')(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[inp1,inp2,inp3,inp4], outputs=[result])\n",
    "model.compile(loss='mean_squared_error', optimizer='rmsprop',metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None)         0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 600)    60320400    concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, None, 128)    340480      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 128)    98816       bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 128)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 128)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           global_max_pooling1d[0][0]       \n",
      "                                                                 global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          65792       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 256)          0           concatenate_1[0][0]              \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 256)          0           add[0][0]                        \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 30)           7710        add_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 60,898,990\n",
      "Trainable params: 578,590\n",
      "Non-trainable params: 60,320,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[type(i) for i in [question_body, question_title, category, answer, target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "           [question_body, question_title, category, answer], [target],\n",
    "            batch_size=128,\n",
    "            epochs=10,\n",
    "            verbose=1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([question_body_test, question_title_test, category_test, answer_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['question_asker_intent_understanding',\n",
    "       'question_body_critical', 'question_conversational',\n",
    "       'question_expect_short_answer', 'question_fact_seeking',\n",
    "       'question_has_commonly_accepted_answer',\n",
    "       'question_interestingness_others', 'question_interestingness_self',\n",
    "       'question_multi_intent', 'question_not_really_a_question',\n",
    "       'question_opinion_seeking', 'question_type_choice',\n",
    "       'question_type_compare', 'question_type_consequence',\n",
    "       'question_type_definition', 'question_type_entity',\n",
    "       'question_type_instructions', 'question_type_procedure',\n",
    "       'question_type_reason_explanation', 'question_type_spelling',\n",
    "       'question_well_written', 'answer_helpful',\n",
    "       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
    "       'answer_satisfaction', 'answer_type_instructions',\n",
    "       'answer_type_procedure', 'answer_type_reason_explanation',\n",
    "       'answer_well_written']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"google-quest-challenge/sample_submission.csv\")\n",
    "\n",
    "for col_index, col in enumerate(target_cols):\n",
    "    sub[col] = predictions[:, col_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "s = now.strftime(\"%d-%m-%Y::%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_items = ['submission', 'kernel_1', *s.split()]\n",
    "name = '_'.join(name_items) + '.csv'\n",
    "\n",
    "sub.to_csv(name, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
